파이썬이 최근에 주목받는 이유 중 하나가 바로 데이터 분석을 위한 다양한 패키지를 제공한다는 점입니다.
데이터 분석을 위해 정교하게 만들어진 통계 패키지를 사용하면 사업계획서를 위한 재무 자료 분석부터 경제적 자유를 이우기 위한 주식 및 부동산 자료 분석까지 직접해 볼 수 있습니다. 
이 장에서는 대표적인 파이썬 패키지인 넘파이, 판다스 , 맷플롯립을 활용해 데이터 분석을 해 보겠습니다.

05-1 데이터 분석 패키지 준비하기
05-2 넘파이로 배열 다루기
05-3 넘파이로 사업성 분석하기
05-4 판다스로 데이터프레임 만들기
05-5 판다스로 통계 데이터 다루기
05-6 실전 통계 분석 맛보기
05-7 맷플롯립으로 그래프 그리기

05-1 데이터 분석 패키지 준비하기

파이썬의 다양한 패키지를 사용하면 다른 데이터 분석 프로그램 못지않게 분석이 가능합니다. 하지만 파이썬 자체가 데이터 분석 프로그램은 아닙니다. 그래서 목적에 맞는 패키지를 따로 설치해야 합니다. 다음은 대표적인 파이썬 데이터 분석 패키지입니다.
┌───────────────────┬───────────────────────────────┬───────────────────────┐
│ 패키지				│ 기능     						│ 주요함수					│
├───────────────────┼───────────────────────────────┼───────────────────────┤
│ 넘파이(numpy)		│ 배열 계산 기능, 반올림, 버리기 기능	│ floor, ceil, power	│
├───────────────────┼───────────────────────────────┼───────────────────────┤
│ 판다스(pandas)		│ 데이터프레임으로 데이터 입력, 가공		│ describe, groupby		│
├───────────────────┼───────────────────────────────┼───────────────────────┤
│ 맷플롯립(matplotlib)	│ 그래프 그리그						│ plot, hist, bar		│
└───────────────────┴───────────────────────────────┴───────────────────────┘

이들 패키지 말고도 math(수학), scipy(통계 분석), statsmodels(통계 모델 작성 및 분석) 등 데이터 분석을 위한 파잌썬 패키지는 많이 있습니다. 그리고 이런 패키지의 사용 방법은 하나의 책으로 담기 어려울 정도로 다양합니다. 따라서 이 책에서는 여러분이 실제로 맞닥뜨릴 수 있는 상황을 중심으로 그 사용번을 간단히 알아보겠습니다.

데이터 분석 패키지 설치하기

아나콘다를 통해서 파이썬을 설치했다면 이미 넘파이, 판다스 , 맷플롯립이 기본적으로 설치되어 있습니다. 처음에 아나콘다를 설치하라고 추천한 이유가 여기에 있습니다. 기본적인 패키지가 모두 설치되어 있어서 이 패키지들을 굳이 따로 설치하지 않아도 되기 때문이죠.

패키지가 설치되어 있지 않다면 다으모가 같이 입력해서 설치하세요. 명령 프롬프트에서 파이썬 실행 위치로 이동한 다음 pip 명열을 입력하면 패키지가 설치됩니다.

C:\User\user\> pip install numpy
# 이처럼 필요한 패키지 이름을 직접 pip 로 설치하는 방법도 있습니다.

마찬가지로 판다스, 맷플롯립과 같은 다른 패키지를 설치하고 싶다면 다으모가 같이 입력합니다.
C:\User\user\> pip install pandas
C:\User\user\> pip install matplotlib


05-2 넘파이로 배열 다루기 == 05-1.py 참고

넘파이는 배열(array)을 다루는 도구이며 숫자로 된 큰 배열 데이터를 다룰 때 진가를 발휘합니다. 예를 들어 엄청나게 많은 데이터 중에서 700이 넘는 숫자만 찾아서 참(True)으로 반환하거나, 특정한 행이나 열에 있는 정보만 반올림하거나 버림하기도 쉽습니다. 또한 복잡한 배열 연산도 가능합니다.

이 절의 목적은 다른 절과 마찬가지로 넘파이의 기능을 정복하는 데 있지 않습니다. 넘파이의 기능을 설명하는 포스팅이나 책은 무궁무진합니다. 당장 구글에 'python numpy'라고만 검색해도 수많은 컴퓨터 전공자, 프로그래머의 엄청난 블로그들이 확인됩니다. 따라서 이 책의 역활은 넘파이의 기능 모두를 설명하는 것이 아니라, 주변에서 흔히 접하는 어떤 문제를 넘파이로 해결할 수 있음을 보여주는 데 있습니다.

자, 그럼 시작해 보겠습니다.

넘파이로 배열 정의하기

뱌열을 표현하기 위해 먼저 넘파이를 임포트 합니다.
┌───────────────────────────────────────────────────────────────────────────┐
│   >>> import numpy as np  # 넘파이를 불러올 때 보통 np로 줄여서 표현합니다.			│
└───────────────────────────────────────────────────────────────────────────┘

넘파이를 불러올 때 np로 줄여서 표현합니다. 이렇게 표현하지 않아도 상관없지만, 정말 많은 책과 포스팅에서 넘파이를 np라고 줄여서 사용하기 때문에 이렇게 사용하는 것을 추천합니다.

넘파이는 기본적으로 '배열'을 표현하기 위한 패키지입니다. 이를 사용해 2차원 배열을 만들어 보겠습니다.
┌───────────────────────────────────────────────────────────────────────────┐
│   >>> a = np.array([[2,3],[5,2]])											│
│   # np.array는 배열을 정의하는 명령입니다. 첫 번째 행부터 리스트로 입력합니다.				│
│																			│
│   >>> a																	│
│   # 배열이 정상적으로 입력되었습니다.												│
└───────────────────────────────────────────────────────────────────────────┘

넘파이의 배열은 지금까지 다뤘던 CSV형 리스트와 아주 비슷한 형태입니다. 앞에서 만든 2차원 배열을 그림으로 표현하면 다음과 같습니다.

        2열
    ┌───┬───┐
    │ 2 │ 3 │
2행	├───┼───┤
    │ 5 │ 2 │
    └───┴───┘

배열 스라이싱 하기

넘파이의 스라이싱 기능은 리스트의 스라이싱 기느오가 유사하지만 숫자를 다루는 데 더 특화되어 있으며 수를 다룰 때 강력합니다. 2차원 배열을 새로 만들겠습니다.
┌───────────────────────────────────────────────────────────────────────────┐
│   >>> d = np.array([[1, 2, 3, 4, 5],[2, 4, 5, 6, 7],[5, 7, 8, 9, 9]])		│
│   # 3 x 5 배열을 만들어 d에 저장합니다.											│
│																			│
│   >>> d																	│
│   array( [[1, 2, 3, 4, 5],												│
│           [2, 4, 5, 6, 7],												│
│           [5, 7, 8, 9, 9]])												│
└───────────────────────────────────────────────────────────────────────────┘

슬라이싱 기능을 사용하려면 각 원소의 인덱스를 알아야 합니다. 이 다차원 배열의 인덱스는 다음과 같습니다. 앞서 다뤘던 CSV형 자료의 인덱스가 넘파이에서 동일하게 매겨집니다.
┌───────────────────────────────────────────────────┐
│       d[0][0]          d[0][1]     d[0][-1]		│
│            ↖       ↗           ↗					│
│   array( [[【1】, 【2】, 3, 4, 【5】],			│
│       ↙  [【2】, 4, 5,   【6, 7】],    d[1:,3:]	│
│   d[1][0] [5, 7, 8,       【9, 9】]])  ↗			│
└───────────────────────────────────────────────────┘

즉, 넘파이로 배열을 표현할 떄 첫 번째 인덱스는 행, 두 번째 인덱스는 열을 가리킵니다. 예를 들어 앞 그림에서 볼때 d[2][4]라고 한다면, 3번째 행, 5번째 열을 가리키는 셈입니다.
┌───────────────────────────────────────────────────────────────────────────────────┐
│   >>> d[1][2]																		│
│   5             # d[1][2]를 행렬식으로 표현하면 [d오른쪽아래에 작은크기로 23] 에 해당하는 수입니다.	│
│   >>> d[1, 2]																		│
│   5             # 이처럼 표현할 수도 있습니다.											│
│   >>> d[1:, 3:]																	│
│   array([[6, 7],																	│
│         [9, 9]]) # 1행 다음, 3열 다음 수만 슬라이싱 했습니다.								│
└───────────────────────────────────────────────────────────────────────────────────┘

배열의 크기 알아내기: shape
배열의 크기는 배열이 몇 개의 행과 열을 가졌는지를 의마합니다. 앞에서 보았던 배열 d는 3X5 배열이라고 표현합니다. 파이썬에서는 3X5를(3, 5)라고 표현하고요. d.shape라고 입력하면 배열 d의 크기를 알 수 있습니다.
┌───────────────────────────────────────────────────────────────────────────────────────────────┐
│   >>> d = np.array([2, 3, 4, 5, 6])               # 1x5 배열을 만듭니다.							│
│   >>> d																						│
│   array([2, 3, 4, 5, 6])																		│
│   >>> d.shape																					│
│   (5,)                                        	# d는 한 개 리스트에 각 다섯 개의 원소를 가지고 있습니다.	│
│   >>> e = np.array([1, 2, 3, 4], [3, 4, 5, 6])    # 2x4 배열을 만듭니다.							│
│   >>> e																						│
│   array([1, 2, 3, 4],																			│
│           [3, 4, 5, 6])																		│
│   >>> e.shape																					│
│   (2, 4)                                      	# e는 두 개 리스트에 각 네 개의 원소를 가지고 있습니다.	│
└───────────────────────────────────────────────────────────────────────────────────────────────┘

배열의 원소 유형 확인하기: dtype

배열에서 원소의 유형(type)이 무엇인지 아는 것은 매우 중요합니다. 예를 들어 배열이 숫자로 되어 있으면 연산을 할 수 있고, 배열이 문자형으로 되어 있다면 정규식을 사용할 수 있습니다. 예를 들어 d.dtype을 입력하면 배열 d의 자료형을 알 수 있습니다.
┌───────────────────────────────────────────┐
│   >>> d.dtype     # 배열 d의 자료형을 확인합니다.	│
│   dtype('int32')  # 정수로 이뤄졌다는 의미입니다.	│
└───────────────────────────────────────────┘

d.dtype의 결괏값으로 dtype('int32')가 출력되었습니다. 이는 배열 d가 정수 원소로 이루어져 있다는 뜻입니다. 배열의 원소 유형에 따른 표기는 다음 표와 같습니다.
% 여기서 16, 32, 64는 용량을 의미합니다. 숫자가 작을수록 작은 숫자만 담을 수 있고, 숫자가 클수록 큰 수를 담을 수 있습니다.

표 5-2 | 배열의 원소 유형에 따른 표기법
┌───────────────────────┬───────────────────┐
│   원소 유형				│   표기법			│
├───────────────────────┼───────────────────┤
│   부호가 있는 정수			│   int(32,64)		│
├───────────────────────┼───────────────────┤
│   부호가 없는 정수			│   int(32,64)		│
├───────────────────────┼───────────────────┤
│   실수					│    int(32,64)		│
├───────────────────────┼───────────────────┤
│   복소수				│	float(32,64)	│
├───────────────────────┼───────────────────┤
│   불(참 거짓을 가지는 자료)	│	bool			│
├───────────────────────┼───────────────────┤
│   문자열				│   string			│
├───────────────────────┼───────────────────┤
│   파이썬 오브젝트			│	object  		│
├───────────────────────┼───────────────────┤
│   유니코드				│   unicode 		│
└───────────────────────┴───────────────────┘

배열 유형 바꾸기: astype()
04장에서는 usercsv 모듈에 저장한 switch()함수를 사용해 바꿀 수 있는 모든 숫자 원소를 숫자형으로 바꿨습니다. 넘파이를 사용하면 유형을 더 쉽게 변경할 수 있습니다. 넘파이에 들어 있는 astype()를 사용하면 됩니다. astype()는 배열의 원소가 가지는 유형을 바꾸는 함수입니다.
┌───────────────────────────────────────────────────────────────────┐
│	>>> data = np.arange(1, 5)	# 1부터 4까지로 이루어진 배열을 생성합니다.	│
│	>>> data.dtype													│
│	dtype('int32')				# 유형을 확인하니 정수입니다.				│
│	>>> data.astype('float64')										│
│	array([1., 2., 3., 4.])		# data 배열의 원소를 모두 실수로 바꿨습니다.	│
│	>>> data.astype('int32')										│
│	array([1, 2, 3, 4])			# 다시 정수로 바꿀 수도 있습니다.			│
└───────────────────────────────────────────────────────────────────┘

넘파이 함수 알아보기
앞으로 자주 쓸 넘파이의 여러 함수를 알아보겠습니다.

0으로 이뤄진 배열 만들기: np.zeros()
np.zeros()함수는 0으로 이뤄진 배열을 만듭니다.
┌───────────────────────────────────────────────────────────────────────┐
│	>>> np.zeros((2, 10))	# 행이 2이고 열일 10이며 각 원소가 0인 배열을 만듭니다.	│
│	array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., ],					│
│			[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., ]])				│
└───────────────────────────────────────────────────────────────────────┘

1로 이워진 배열 만들기: np.ones()
np.ones() 함수는 1로 이뤄진 배열을 만듭니다.
┌───────────────────────────────────────────────────────────────────────┐
│	>>> np.ones((2, 10))	# 행이 2이고 열일 10이며 각 원소가 1인 배열을 만듭니다.	│
│	array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., ],					│
│			[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., ]])				│
└───────────────────────────────────────────────────────────────────────┘

연속형 정수 생성하기: np.arange()
np.arange()함수느 특정 범위에 있는 원소를 자동으로 만듭니다.
┌───────────────────────────────────────────────────────────────────────────┐
│	>>> np.arange((2, 10))		# 2 이상 10 미만의 원소로 이뤄진 1차원 배열을 만듭니다.	│
│	array([2, 3, 4, 5, 6, 7, 8, 9])											│
└───────────────────────────────────────────────────────────────────────────┘

행과 열을 바꾸기: np.transpose()
배열을 다루다 보면 행과 열을 바꿔야 하는 상황이 종종 발생하지요. 이때는 transpose() 함수를 쓰면 됩니다.
┌───────────────────────────────────────────────────────────────────────────┐
│	>>> a = np.ones((2, 3))			# 원소가 전부 1인 2x3 배열을 만듭니다.			│
│	>>> a																	│
│	array([	[1., 1., 1.],													│
│			[1., 1., 1.]	])												│
│	>>> b = np.transpose(a)			# a에 저장된 배열의 행과 열을 바꿔 b에 저장합니다.	│
│	>>> b																	│
│	array([	[1., 1.],														│
│			[1., 1.],														│
│			[1., 1.]])														│
└───────────────────────────────────────────────────────────────────────────┘

배열의 사칙 연산
배열끼리도 사칙 연산을 할 수 있습니다. 그런데 곱셈과 나눗셈의 경우에는 행력의 연산 방식과 다르므로 꼭 알아두어야 합니다. 사칙 연산에 사용할 (3,3) 크기를 가진 서로 다른 배열 arr1, arr2를 정의하겠습니다.
┌───────────────────────────────────────────────────────┐
│	>>> arr1 = np.array([[2, 3, 4], [6, 7, 8]])			│
│	>>> arr2 = np.array([[12, 23, 14], [36, 47, 58]])	│
└───────────────────────────────────────────────────────┘

배열의 덧셈
arr1과 arr2를 더하면 같은 자리의 원소끼리 더합니다. 예를 들어 새로운 배열의 [0][0] 자리에는 arr1[0][0]인 2와 arr2[0][0]인 12를 더한 값인 14가 저장됩니다.
┌───────────────────────────┐
│	>>> arr1 + arr2			│
│	array([	[14, 26, 18],	│
│			[42, 54, 66])	│
└───────────────────────────┘

배열의 곱셈
배열끼리 곱하면 행렬처럼 곱셈이 진행되는 것이 아니라 같은 자리의 원소끼리 곱합니다.
┌───────────────────────────────────────────────────┐
│	>>> arr1 * arr2									│
│	array([	[24, 69, 56],							│
│			[216, 329, 464])	# 행렬의 곱셈과 다릅니다.	│
└───────────────────────────────────────────────────┘

배열의 나눗셈
배열을 배열로 나누면 같은 자리의 원소끼리 나눕니다.
┌───────────────────────────────────────────────────────────────────────────────────┐
│	>>> arr1 / arr2																	│
│	array([	[0.16666667 0.13043478 0.28571429],										│
│			[0.16666667 0.14893617 0.13793103])	# array[0][0] =2/16 = 0.16666667	│
└───────────────────────────────────────────────────────────────────────────────────┘

크기가 서로 다른 배열끼리 더하기
(3, )크기의 배열 arr3을 다음과 같이 정의합니다.
┌───────────────────────────────────────────┐
│	>>> arr3 = np.array([100, 200, 300])	│
└───────────────────────────────────────────┘

아까 만들었던 arr1과 arr3를 더할 수 있을까요? 넘파이에서는 가능합니다. 이처럼 서로 다른 크기의 배열을 연산하는 기능을 브로드캐스팅(broadcasting) 기능이라고 합니다. 인공지능에서 많이 쓰이는 유용한 기능이라고 하니 알아둘 필요가 있겠네요.
┌───────────────────────────────────────────────┐
│	>>> arr1.shape								│
│	(2,3)										│
│	>>> arr3.shape								│
│	(3,)			# arr1과 arr3는 크기가 다릅니다.	│
│	>>> arr1 + arr3								│
│	array[	[102, 203, 304],					│
│			[106, 207, 308]]					│
└───────────────────────────────────────────────┘

계산된 결과를 보면 arr3의 값이 arr1[0]과 arr1[1]에 각각 더해졌음을 확인할 수 있습니다.

브로드캐스팅이 되지 않는 경우도 있습니다. 예를 들어 보겠습니다. (10,) 크기의 배열 arr4를 만들어 (2,3) 크기의 배열 arr1과 더하면 어떻게 될까요?

┌───────────────────────────────────────────────┐
│	>>> arr4 = np.array([1,2,3,4,5,6,7,8,9,10])	│
│	>>> arr4.shape								│
│	(10,)                                       │
│	>>> arr1.shape                              │
│	(2,3)                                       │
│	>>> arr1 + arr4                             │
└───────────────────────────────────────────────┘
결과
┌───────────────────────────────────────────────────────────────────────────┐
│	예외가 발생했습니다. ValueError												│
│	operands could not be broadcast together with shapes (2,3) (10,) 		│
│	  File "C:\000_002_Python\01_Start\5장\05-1.py", line 111, in <module>	│
│	    arr1 + arr4															│
│	                                                                        │
│	# 행과 열의 크기가 모두 다 다른 배열은 더할 수 없네요.								│
└───────────────────────────────────────────────────────────────────────────┘

즉, 특정 조건을 만족해야 두 배열을 더할 수 있습니다. (2,1) 크기의 arr5 벼열으 만들어서 arr1배열에 더해 보겠습니다.
┌───────────────────────────────────────────────────────────────────────┐
│	>>> arr5 = np.array([[9], [3]])										│
│	>>> arr5.shape														│
│	(2,1)                                       						│
│	>>> arr1															│
│	array([	[2, 3, 4], 													│
│			[6, 7, 8]])													│
│	>>> arr1 + arr5                             						│
│	array([	[11, 12, 13], 												│
│			[9, 10, 11]])	# arr1[0,:](1행)에 arr5[0][0]인 9를 각각 더합니다.	│
│	# (2,3)크기를 가지는 arr1과 더하니 브로드캐스팅이 됩니다.						│
└───────────────────────────────────────────────────────────────────────┘

파이썬 리스트와 배열의 차이점
넘파이로 만든 배열과 04장에서 배운 CSV형 리스트는 생김새가 비슷하지만 같은 자료형은 아닙니다. 둘의 차이점을 간단치 알아보겠습니다.
┌───────────────────────────────────────────────────────────────────────────┐
│	>>> d = np.array([[1, 2, 3, 4, 5], [2, 4, 5, 6, 7], [5, 7, 8, 9, 9]])	│
│	# 3X5 배열 d를 정의합니다.                                                  	│
│	>>> d_list = [	[1, 2, 3, 4, 5],                                        │
│					[2, 4, 5, 6, 7],                                        │
│					[5, 7, 8, 9, 9]]                                        │
│	# 배열 d와 똑같이 생긴 CSV형 리스트를 만들어 d_list 객체에 저장합니다.                	│
│	>>> d_list                                                              │
│	[[1, 2, 3, 4, 5], [2, 4, 5, 6, 7], [5, 7, 8, 9, 9]]                     │
│	# array가 붙어 있지 않다는 점을 뺴면 d와 거의 같습니다.                            	│
│	>>> type(d_list)                                                        │
│	<class 'list'>                                                          │
│	# CSV형 객체의 자료형은 리스트입니다.                                           	│
│	>>> d_list[:2] = 0                                                      │
│	예외가 발생했습니다. TypeError                                               	│
│		can only assign an iterable                                         │
│		File PATH, line 138, in <module>                                    │
│		d_list[:2] = 0                                                      │
│	# d_list의 두 번째 원소까지 슬라이싱 해 0을 저장하라고 명령하면 오류가 발생합니다.			│
│	>>> d[:2] = 0                                                           │
│	# 배열 d의 두 번째 원소까지 슬라이싱 해 0을 저장하라고 명령합니다.						│
│	>>> d                                                                   │
│	array[	[0 0 0 0 0],                                                    │
│			[0 0 0 0 0],                                                    │
│			[5 7 8 9 9]]                                                    │
│	# 두 번째 리스트까지 모든 원소에 0을 저장합니다.                                   	│
└───────────────────────────────────────────────────────────────────────────┘

이러한 기능은 대량의 데이터를 한꺼번에 처리할 때 리스트보다 배열이 경쟁력 있음을 보여 줍니다.

인덱싱과 슬라이싱 연습하기
배열을 활용할 때 인덱싱과 슬라이싱을 자유자재로 할 수 있으면 자료를 마음껏 활용할 수 있습니다. 먼저 0부터 9까지 원소를 가지는 배열을 만들어 봅니다.
┌───────────────────────────────────────────┐
│	>>> arr4 = np.arange(10)				│
│	>>> arr4								│
│	# array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])	│
└───────────────────────────────────────────┘

배열에서 슬라이싱을 하는 방법은 기본적으로 리스트에서 슬라이싱을 하는 방식과 유사합니다. 예를 들어 arr4[:5]라고 하면 arr4[0]부터 arr4[4]까지 총 다섯 개 원소를 슬라이싱합니다.
┌───────────────────────────────────────────────────────────────┐
│	>>> arr4[:5]												│
│	array([0, 1, 2, 3, 4])	# 0부터 4까지 5개의 원소를 슬라이싱합니다.	│
└───────────────────────────────────────────────────────────────┘

arr[-3:]을 입력하면 뒤에서 세 번째 원소부터 마지막 원소까지 슬라이싱을 합니다.
┌───────────────────────┐
│	>>> arr4[-3:]		│	
│	array([7, 8, 9])	│
└───────────────────────┘

리스트가 여러 개 있으면 어떻게 할까요? 앞에서 만든 arr1 뱌열을 사용해 보겠습니다.
┌───────────────────────────────────────────────┐
│	>>> arr1                                    │
│	# array([[2, 3, 4], [6, 7, 8]])             │
│	>>> arr1[1,2]                               │
│	# 8											│
│	# arr1에서 두 번째 리스트의 세 번째 원소를 선택합니다.	│
│	>>> arr1[:, 2]								│
│	# array([4, 8])                             │
│	# 모든 리스트의 세 번째 원소를 슬라이싱 합니다.        	│
└───────────────────────────────────────────────┘

Do it 설문지 데이터 전처리하기 == 05-2.py 참조
지금까지 배운 넘파이 사용 방법을 연습하기 위해 CSV 파일에 저장된 데이터를 전처리하는 간단한 실습을 진행하겠습니다. 실습을 위해 5점 만점으로 된 설문 조사 결과가 quest.csv라는 파일에 저장되어 있다고 가정하겠습니다.
% 데이터 전처리(data preprocessting)란 데이터를 분석하기 좋게 미리 가공하는 일을 말합니다.

설문 조사의 각 항목을 1점부터 5점까지 입니다. 그런데 살펴보면 6이라는 숫자가 보이는군요. 이 자료를 파이썬으로 불러온 다음 잘못 입력된 점수를 수정해 보겠습니다.
┌───────────────────────────────────────────────────────────────────────────────────────────┐
│	import os, sys                                                                        	│
│	sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))		    │
│	from Function import usercsv, Learning                                                  │
│	import numpy as np                                                                      │
│	                                                                                        │
│	fileName = 'quest.csv'                                                                  │
│	Learning.MoveLearningDataDir()                  # quest.csv를 저장한 경로로 이동             	│
│	quest = np.array(usercsv.switch(usercsv.opencsv(fileName, 0)))                          │
│	# quest.csv 파일을 열어 숫자 원소를 실수형으로 바꾼 다음 배열 형태로 quest 객체에 저장합니다.              	│
│	quest                                                                                   │
│	# array([[1., 2., 1., 2., 2.],                  # quest.csv 파일의 값이 배열로 잘 저장되었네요.  	│
│	#       [1., 3., 2., 3., 2.],                                                           │
│	#       [1., 4., 3., 3., 3.],                                                           │
│	#       [2., 5., 4., 4., 4.],                                                           │
│	#       [2., 5., 6., 2., 5.],                                                           │
│	#       [3., 6., 4., 2., 5.],                                                           │
│	#       [3., 5., 4., 1., 6.],                                                           │
│	#       [3., 5., 5., 1., 3.]])                                                          │
│	quest > 5                                       # 간단한 조건문을 입력해 볼까요?               	│
│	# array([[False, False, False, False, False],   # 5보다 큰면 True, 작거나 같으면 False입니다.	│
│	#        [False, False, False, False, False],											│
│	#        [False, False, False, False, False],                                           │
│	#        [False, False, False, False, False],                                           │
│	#        [False, False,  True, False, False],                                           │
│	#        [False,  True, False, False, False],                                           │
│	#        [False, False, False, False,  True],                                           │
│	#        [False, False, False, False, False]])                                          │
│	quest[quest > 5]                                # 인덱싱을 활용해 5보다 큰 수만 가져옵니다.       	│
│	# array([6., 6., 6.])                                                                  	│
│	quest[quest > 5] = 5                            # 5보다 큰 숫자가 전부 5로 바꿉니다.           	│
│	quest                                                                                  	│
│	# array([[1., 2., 1., 2., 2.],                  # 5보다 큰 숫자가 전부 5로 바뀌었네요           	│
│	#        [1., 3., 2., 3., 2.],                                                         	│
│	#        [1., 4., 3., 3., 3.],                                                          │
│	#        [2., 5., 4., 4., 4.],                                                          │
│	#        [2., 5., 5., 2., 5.],                                                          │
│	#        [3., 5., 4., 2., 5.],                                                          │
│	#        [3., 5., 4., 1., 5.],                                                          │
│	#        [3., 5., 5., 1., 3.]])                                                         │
│	usercsv.writecsv('resultcsv.csv', list(quest))                                          │
│	# 결과물을 다시 'resultcsv.csv'라는 이름으로 저장                                               	│
└───────────────────────────────────────────────────────────────────────────────────────────┘

저장 경로로 가서 resultcsv.csv 파일을 열면 다음과 같이 5보다 큰 수가 모두 5로 바뀌어 저장되었음을 확인해 볼 수 있습니다.
┌───────────────────────────────────┐
│	array([[1., 2., 1., 2., 2.],  	│
│	       [1., 3., 2., 3., 2.],  	│
│	       [1., 4., 3., 3., 3.],	│
│	       [2., 5., 4., 4., 4.],	│
│	       [2., 5., 5., 2., 5.],	│
│	       [3., 5., 4., 2., 5.],	│
│	       [3., 5., 4., 1., 5.],	│
│	       [3., 5., 5., 1., 3.]])	│
└───────────────────────────────────┘

05-3 넘파이로 사업성 분석하기	== 05-3.py 참조
 
넘파이는 주로 어디에서 유용하게 사용할까요? 특히 숫자를 많이 다루는 전문 분야, 연구와 관련된 분야일수록 대규모 데이터를 다워야 할 일이 많기 때문에 넘파이를 유용하게 사용합니다. 이번에는 우리가 검토해야 할 사업이 있다고 가정하고, 그 사업의 사업성을 분석하며 넘파이를 제대로 사용하는 방법을 알아보겠습니다.

사업성 분석이란
사업성 분석이란 간단히 말해 이 사업을 했을 때 이익이나 손해가 어느 정도 나올지 따져보는 것입니다.

경제적 타당성의 개넘
경제적 타당성은 간단히 말해 이 사업이 우리에게 비용 대비 얼마나 많은 효욜을 가져다 줄 수 있는지를 나타내는 개념입니다. 이를 본석하는 핵심 지표는 순현재가치(NPV)와 내부수익률(IRR)입니다.
┌───────────────────────────────────────────────────────────────────────────────┐
│	- 순현재가치(Net Present Value, NPV): 할인된 현금 흐름의 값을 모두 더한 값을 말합니다.		│
│	- 내부수익률(Internaal Rate of Return, IRR): 순현재가치를 0으로 만드는 할인율을 말합니다.	│
└───────────────────────────────────────────────────────────────────────────────┘

개념이 쉽지 않죠? 걱정하지 마세요. 다음에 나오는 세부 지표의 값을 구하면 핵심 지표의 값은 넘파이에 내장된 함수로 쉽게 값을 구할 수 있습니다. 값을 구해야 할 세부 지표는 다음과 같습니다.
┌───────────────────────┬───────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────┐
│	이름					│	공식					│	설명																							│
├───────────────────────┼───────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────┤
│	비용(C)				│	∑C					│	사업을 만드는 데 들어가는 모든 비용입니다.																│
├───────────────────────┼───────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────┤
│	수입(B)				│	∑B					│	사업을 하면서 발생하는 이익입니다.																	│
├───────────────────────┼───────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────┤
│	현금 흐름(CF)			│	CF = B - C			│	수입에서 비용을 제외한 금액입니다.																	│
├───────────────────────┼───────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────┤
│	연차(n)				│	-					│	총 사업 기간입니다.																				│
├───────────────────────┼───────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────┤
│	할인율(r)				│	-					│	미래의 현금 흐름을 현재 기준으로 환산할 떄 적용하는 비율입니다. 여기에서는 사회적 할인율을 적용합니다.					│
├───────────────────────┼───────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────┤
│	현금 흐름의 현재 가치(PV)	│	PV = CFk/(1 + r)k	│	할인율을 적요한 k년차 현금 흐름의 현재 가치를 의미합니다.													│
│						│						│	(F 옆 k는 아래의 작인 k, r)옆 k는 제곱의 k)															│
├───────────────────────┼───────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────┤
│	순현재가치(NPV)		│	NPV = ∑(CFk/(1+r)k)	│	투자 안의 매년 현재 가치(PV)를 다 더한 값입니다. 이 값이 0보다 크면 해당 투자 안에 사업성이 있다고 해석할 수 있습니다.	│
│						│						│	(F 옆 k는 아래의 작인 k, r)옆 k는 제곱의 k)															│
└───────────────────────┴───────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────┘
% 사회적 할인율이란 공공사업을 분석할 때 사용하는 미래 가치의 할인율을 말하며 2020년 6월 기준 4.5%를 사용할 수 있습니다.

여기서 비용, 수입, 현금 흐름, 연차는 개념이 단순합니다. 그런데 '할인율'과 '자본의 현재 가치'는 처음 이 개념을 접한 사람에게는 어렵게 느껴지겠네요. 자본의 현재 가치를 가상으로 구해 보면서 이해해 보겠습니다.

Do it 자본의 현재 가치 구하기	== 05-3.py 참조
1. 언제나 사용할 모듈을 먼저 임포트 합니다. numpy 모듈을 np로 임포트 하겠습니다.
2. 할인율과 현금 흐름을 설정합니다. 현금 흐름은 100억 원(단위:억원), 할인율을 5%라고 가정하겠습니다. discount에는 할인율, cashflow에는 현금 흐름을 저장합니다.
3. 현재 가치(PV)를 구하는 공식(PV = CFk/(1 + r)k)을 다음과 같은 함수로 만들겠습니다. 연차를 입력하면 그 해당 연차의 혐금 흐름의 현재 가치를 게산할 수 있습니다.
4. 공식을 사용해 보겠습니다. 완공 후 1, 2년 차일 때 현재 가치는 다음과 같습니다.
5. 20년 동안 발생할 현재 가치를 모두 한 번에 구할 수도 있습니다.
┌───────────────────────────────────────────────────────┐
│	>>> import numpy as np  # 먼저 넘파이를 임포트합니다.		│
│														│
│	>>> discount = .05      # 할인율은 5%입니다.				│
│	>>> cashflow = 100      # 현금 흐름은 100(억 원)입니다.	│
│														│
│	>>> def presentvalue(n):							│
│	   return (cashflow / (1 + discount) ** n)			│
│	# 자본의 현재 가치를 구하는 공식을 함수로 만듭니다.				│
│														│
│	>>> print(presentvalue(1))							│
│	95.23809523809524									│
│	>>> print(presentvalue(2))							│
│	90.70294784580499									│
└───────────────────────────────────────────────────────┘

이처럼 할인율 개념을 파이썬으로 간단하게 확인해 보는 것도 재미있는 방법입니다. 이제 조금 과감하게 진도를 나가보겠습니다.

Do it 놀이공원 사업의 사업성 분석하기	== 05-4.py 참조
이제 더 구체적인 상황을 가정하고 넘파이를 활용해 실습해 보겠습니다.

---------------------------------------------------------------------------------------------------------------------------------------------------------------------
이런 상황이라면?

놀이공원 사원의 사업성르 분석하자.[난이도 1, 완성코드 05\park.py]

건설회사 사장님은 놀이공원을 여는 것이 꿈입니다. 건설사업이 성공해서 돈을 많이 벌어서 이제는 놀이공원에 한번 도전해도 괜찮을 것 같습니다. 건설회사 사장님은 자신이 모든 돈과 지금 가진 신용으로 이 놀이 공원을 지을 수 있을지, 지었을때 이익이 날지 손해가 날지 알고 싶습니다. 여기저기 물어보니 사업의 타당성을 조사하는 방법이 있다고 합니다. 자, 그럼 한번 같이 배워볼까요?
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
사업성을 분석하기에 앞서 다음 표를 살펴보세요. 가상의 사업 지표를 만들어 놓았습니다. 이번 실습에서는 여기 있는 수치를 바탕으로 사업성을 분석하겠습니다.
% 여기서는 실습의 편의를 위해 공사를 시작하는 시점을 1년 차로 가정하겠습니다. 일반적으로 운영 수입이 발생하는 시점을 기준년도로 본디ㅏ.
% 가상의 사업을 분석하는 과정에서 분석 기간은 사업에 따라서 달라질 수 있습니다. 이 책에서 제시하는 분석 기간과 실제 분석 기간이 다를 수 있으니 유의하세요.



1. 세부 지표 값 구하기

제대로 현금 흐름을 계산하려면 지출과 수입이 어떻게 발생하는지를 심도 있게 조사해야 합니다. 이 실습의 목적은 최종 타당성 지수를 구하느 납ㅇ법을 이해하는 데 있으니, 최종 현금 흐름 자료는 간단하게 도출하겠습니다.

먼저 첫 번째 해와 두 번째 해를 살펴보면 각각 750억 원과 250억 원의 비용만 발생합니다. 그리고 세 번째 해부터 18년 동안 연간 150억 원의 수입과 50억 원의 비용이 발생해 총 100억 원의 수익이 발생한다고 되어 있습니다.
┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│	import os, sys																								│
│	sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))								│
│	from Function import Learning, usercsv																		│
│	import numpy as np																							│
│																												│
│	loss = [-750, -250]																							│
│	# 1, 2년 차에 발생한 비용입니다.																					│
│	profit = [100] * 18																							│
│	print(profit)																								│
│	# [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]				│
│	cf = loss + profit																							│
│	print(cf)																									│
│	# [-750, -250, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]	│
│	# 총 20년 동안 현금 흐름을 리스트로 만들어 cf에 저장했습니다.																│
│	len(cf)																										│
│	# 20																										│
│	# 총 20개의 정보가 있음을 확인했습니다.																				│
│	cashflow = np.array(cf)																						│
│	# 이제 cf를 배열로 만들어 cashflow에 저장합니다.																		│
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

2. 순현재가치(NPV)와 내부수익룰(IRR) 구하기
순현재가치와 내부수익률을 구하는 함수는 넘파이에 내장되어 있습니다. 두 값을 구하는 함수는 각각 다음과 같습니다.
┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│	import numpy_financial as np_f	# NEP 32에 따라 npv 함수가 NumPy 버전 1.20에서 제거되었습니다. 이 함수의 대체 기능은 numpy_financial 라이브러리에서 사용가능	│
│	np.npv(할인율, 현금 흐름)			# 순현재가치																								│
│	np.irr(현금 흐름)					# 내부수익률																								│
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

두 핵심 지표를 구하는 데 필요한 값은 앞에서 거의 다 구했네요. 할인율은 4.5%로 가정하겠습니다. 이제 np.npv()와 np.irr() 함수를 사용하면 아주 손쉽게 순현재가치와 내부수익률을 구할 수 있습니다.
┌───────────────────────────────────────┐
│	>>> import numpy_financial as np_f	│
│	>>> npv = np_f.npv(0.045, cashflow)	│
│	>>> npv								│
│	174.4011295118405	# 순현재가치를 출력	│
│	>>> irr = np_f.irr(cashflow)		│
│	>>> irr								│
│	0.06434936937255675	# 내부수익률을 울력	│
└───────────────────────────────────────┘

순현재가치는 약 174.4억이고, 내부수익률은 6.4% 정도가 나왔습니다. 과연 이 사업은 수익서이 있다고 해석할 수 있을까요?

3. 핵심 지표 값 해헉하기
사실 재무적 타당성은 순현재가치나 내부수익률의 수치를 구하는 일보다는 그 수치를 해석하는 일이 훨씬 더 중요합니다. 먼저 내부수익률부터 해석해 보겠습니다. 약 6.4%였지요.
┌───────────────────────────────────┐
│	>>> irr							│
│	0.06434936937255675	# 내부수익률	│
└───────────────────────────────────┘

이때는 할인율에 따라 그 사업이 수익성이 있는지 없는지가 결정됩니다. 가정한 할인율은 4.5%였고, 6.4%는 4.5% 보다 높기 때문에 수익성이 있다고 할 수 있습니다. 하지만 이자를 해마다 10%씩 내야 한다고 가정하면 다시 생각해야 합니다. 18년 동안 운영한다고 가정했을 때 내부수익률이 6.4%이므로 10%보다 더 작습니다. 즉, 현실에서는 할인율뿐만 아니라 여러 요소를 고려해 사업의 수익성을 분석해야 합니다.
┌───────────────────────────────────┐
│	>>> npv							│
│	174.4011295118405	# 순현재가치	│
└───────────────────────────────────┘

일단 여기에서는 할인율을 4.5%로 지정했으므로 이 자료만으로도 사업성이 있는지 판단할 수 있습니다. 현재 이 프로젝트의 가치는 174억으로서 이 정도 수익을 올릴 수 있다면, 이 사업은 순현재가치를 봤을 때도 사업성이 있는 것으로 판단할 수 있습니다.

참고로 엑셀에서 npv 함수, irr 함수를 사용해도 쉽게 이 값들을 구할 수 있습니다. 함수와 관련해서 엑셀과 파이썬은 모두 계산기 역학만 할 뿐이므로 어떤 프로그램을 사용할지는 여러분의 몫입니다. 이미 말씀드린 것처럼 데이터를 눈으로 확인하면서 가공할 때는 엑셀과 같은 스프레드시트 프로그램이 파이썬보다 훨씬 유용합니다. 

사업수익률 계산법은 굳이 재무나 회계 전공이 아니라 하더라도 매우 중요합니다. 공공이든 민간이든, 모든 사업을 할 때 들어가는 돈(비용)과 사업으로 벌어들일 돈(수입)에 대한 계산은 필수이기 때문입니다. 그러므로 직장인이나 취업준비생들이 이 계산법을 알아둔다면 나중에 유용하게 쓸 수 있을 때가 꼭 있을리라 생각합니다.

05-4 판다스로 데이터프레임 만들기 == 05-5.py 참조

판다스(pandas)는 파이썬 환경에서 많이 사용하는 패키지 중 하나입니다. 데이터를 다루려면 넘파이, 판다스, 맷플롯립 등 이 세가지 패키지의 사용법을 필히 익혀야 합니다. 앞에서 알아본 넘파이가 수치 계산에 최적화된 패키지라면, 판다스는 데이터 처리에 최적화된 패키지라고 할 수 있습니다.

데이터프레임이란?
데이터프레임(dataframe)이란 앞에서 다룬 배열과는 또 다른 형태로 데이터를 쉽게 가공하기 위한 일종의 틀을 의미합니다. 데이터프레임에 데이터를 넣으면 향후 살펴볼 것처럼 매우 다양한 방법으로 가공할 수 있습니다.

DataFrame() 함수를 사용하면 딕셔너리형 자료를 판다스로 가공할 수 있는 데이터프임으로 만들 수 있습니다. 데이터프레임을 간단히 만들어 보겠습니다. 먼저 딕셔너리형 자료르 만들고 DataFrame()함수를 사용합니다.
┌───────────────────────────────────────────────────────────────────┐
│	>>> import pandas as pd											│
│	# 넘파이를 임포트 할 때와 마찬가지로 pd라는 줄임말을 판다스를 임포트 합니다.		│
│	>>> data = {	'name' : ['Mark', 'Jane', 'Chris', 'Ryan'],		│
│					'age' : [33, 32, 44, 42],						│
│					'score' : [91.3, 83.4, 77.5, 87.7]}				│
│	# 임의의 딕셔너리형 자료를 data 객체에 저장합니다.							│
│	>>> df = pd.DataFrame(data)										│
│	# DataFrame() 함수로 data 객체를 데이터프레임으로 만들어 df 객체에 저장합니다.	│
└───────────────────────────────────────────────────────────────────┘

df에 값이 어떻게 들어갔는지 구경해  볼까요? df를 한번 출력해 보겠습니다.
┌───────────────────────────────────────────┐
│	>>> df                                  │
│   	name  age  score                    │
│	0   Mark   33   91.3                    │
│	1   Jane   32   83.4                    │
│	2  Chris   44   77.5                    │
│	3   Ryan   42   87.7					│
│	# 데이터프레임 형태의 자료가 df에 저장되어 있습니다.	│
└───────────────────────────────────────────┘

마치 엑셀에 넣은 것처럼 가지련하게 정리된 형태로 출력된 것을 확인할 수 있습니다. 이처럼 정상적으로 데이터프레임이 형성되었다면 이제 판다스에 들어 있는 수많은 기능을 사용할 수 있게 됩니다. 아주 간단한 연산 몇 가지를 해보겠습니다.

sum(): 합계
sum()으로 특정 값들의 함게를 구할 수 있습니다. 여기에서 별다른 가공을 하지 않고 그냥 sum()함수를 사용하겠습니다.
┌───────────────────────────────────────────────────────────────────────────┐
│	>>>df.sum()                     										│
│	name     MarkJaneChrisRyan      										│
│	age                    151      										│
│	score                339.9      										│
│	dtype: objec															│
│	# 'name'은 문자열이므로 연산을 진행할 수 없고, 자동으로 age와 score만 연산을 진행했습니다.	│
└───────────────────────────────────────────────────────────────────────────┘
mean() : 편균
판다스에서도 넘파이와 마찬가지로 mean() 함수로 평균을 쉽게 구혈 수 있습니다.
┌───────────────────────────────────────────────┐
│	>>>df.mean()    							│
│	age      37.750 							│
│	score    84.975 							│
│	dtype: float64								│
│	# 마찬가리로 age와 score에 대해서만 평균을 구했습니다.	│
└───────────────────────────────────────────────┘
데이터 선택하기
특정 데이터를 선택하는 방법을 알아보겠습니다. 데이터를 선택하는 방법은 'df.[key 값]' 혹은 'df.key 값'입니다. 예를 들어 age를 선택하고 싶다면 df['age']나 df.age를 입력하면 됩니다. df.age와 같이 입력할 경우 가끔 오류가 발생할 수 있어 가급적 df.['age']와 같이 사용하는 것을 추천합니다.
┌───────────────────────────────────────────────────────────────┐
│	>>> df.age													│
│	0    33														│
│	1    32                                                     │
│	2    44                                                     │
│	3    42                                                     │
│	Name: age, dtype: int64	# dtype:int64는 이 열의 유형이 정수라는 의미	│
│	>>> df['age']												│
│	0    33      												│
│	1    32      												│
│	2    44      												│
│	3    42      												│
│	Name: age, dtype: int64 # dtype:int64는 이 열의 유형이 정수라는 의미	│
└───────────────────────────────────────────────────────────────┘

Do it CSV 파일 불러와 데이터 프레임으로 만들기 == 05-6.py 참조
이제 CSV 파일을 불러와 판다스로 가공하는 실습을 진행해 보겠습니다.

1. 05장 실습 파일 폴더에서 apt.csv 파일을 찾으세요. 5억 원 미만 아파트 정보가 저장되어 있습니다. 이번에는 국토교통부 웹 사이트에서 내려받은 실제 데이터를 실습하기 쉬운 형태로 미리 가공해 놓았습니다. 이 파일을 실습을 진행할 경롤로 옮깁니다.

2. pandas를 pd라는 줄임말로 임포트 합니다. 아나콘다를 통해서 파이썬을 설치했다면 별도의 설치 작업 없이 바로 판다스를 임포트 할 수 있습니다.
┌───────────────────────────────────────────────────────────────────────────────────┐
│	>>>import pandas as pd                                                          │
│	>>>import re, os, sys															│
│	>>>sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))	│
│	>>>from Function import usercsv, Learning										│
│												                                	│
│	>>>path = Learning.MoveLearningDataDir()										│
└───────────────────────────────────────────────────────────────────────────────────┘

3. 판다스로 CSV 파일을 불러올 때는 read_csv()함수를 사용합니다. pd.read_csv('apt.csv')를 입력하면 apt.csv의 자료가 자동으로 데이터프레임으로 변환됩니다. 변환한 값을 저장할 객체 이름은 바로 데이터프레임임을 파악할 수 있게 약자인 df로 정의하겠습니다.
┌───────────────────────────────────────────────────────────────────────────────────────────────┐
│	>>> df = pd.read_csv('apt.csv')                                                             │
│	Traceback (most recent call last):                                                          │
│	  File "<stdin>", line 1, in <module>                                                       │
│	  # ... #                                                                                   │
│	  # 생략 #                                                                                  	│
│	  # ... #																					│
│	UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 0: invalid start byte	│
│	# 정확하게 입력했는데 왜 이런 오류 메세지가 나타날까요?													│
└───────────────────────────────────────────────────────────────────────────────────────────────┘

그런데 오류가 발생합니다. 사실 이 문제는 한글을 쓰는 우리가 파이썬을 비롯해 컴퓨터 프로그램을 사용할 때 항상 골머리를 앓는 문제입니다. 바로 인코딩 방식 때문에 가끔 이런 문제가 나타나는데요. 이럴 떄는 당황하지 말고 오류 메세지를 그냥 구글 창에 입력하면 대부분답이 나옵니다. 이 경우에는 인코딩을 cp949로 하면 문제가 해결됩니다. 만약 엑셀에서 저장할 때 UTF-8로 저장해싿면, encoding='uft8'로 지정해 주세요.
%인코딩 오류는 자주 발생하므로 이를 해결해 주는 이 코드는 외워두는 것을 추천합니다.
┌───────────────────────────────────────────────────────┐
│	>>> df = pd.read_csv('apt.csv', encoding = 'cp949')	│
│	>>> 												│
└───────────────────────────────────────────────────────┘

df에 몇 개의 자료가 들어갔는지 확인해 볼까요?
┌───────────────────────────────────────┐
│	>>> len(df) 						│
│	42758	# 42758 개의 자료가 들어 있습니다.	│
└───────────────────────────────────────┘

Do it 데이터프레임 살펴보기
이제 데이터프레임으로 가져온 자료를 여러 가지 방법으로 살펴보겠습니다.

1. 처음이나 마지막 자료 일부만 출력하기
이렇게 많은 자료를 다룰 때는 먼저 df에 자료가 어떻게 들어가 있는지 한번 보고 싶어집니다. 이럴 때 사용하는 명령어가 head() 함수와 tail()함수입니다.
% 면적의 단위는 1제곱미터(㎡), 가격의 단위는 1만 원입니다.
┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│	>>> df.head()																								│
│	            지역   번지   본번  부번           아파트       면적    계약년월  계약일     가격   층  건축년도           도로명 	│
│	0  강원도 강릉시 견소동  202  202   0          송정한신   59.800  201910    4  10900   5  1997   경강로2539번길 8     	│
│	1  강원도 강릉시 견소동  202  202   0          송정한신  116.175  201910   31  18500  10  1997   경강로2539번길 8     	│
│	2  강원도 강릉시 견소동  289  289   0  송정해변신도브래뉴아파트   84.990  201910    5  25000   6  2005  경강로2539번길 22   	│
│	3  강원도 강릉시 견소동  289  289   0  송정해변신도브래뉴아파트   84.990  201910   12  20600   3  2005  경강로2539번길 22   	│
│	4  강원도 강릉시 견소동  289  289   0  송정해변신도브래뉴아파트   84.990  201910   20  20500   1  2005  경강로2539번길 22   	│
│	# df.head()는 df에서 처음 5개 행만 출력합니다.                                                                      	│
│	>>> df.tail()                                                                                               │
│	                 지역      번지   본번  부번         아파트     면적    계약년월  계약일     가격   층  건축년도       도로명	│
│	42753  충청북도 충주시 호암동   547-6  547   6        호반현대  59.76  201910   29   7000   3  1994   신촌2길 28     	│
│	42754  충청북도 충주시 호암동  221-23  221  23  호암리버빌(1단지)  84.68  201910    5  12000  15  2002  원호암5길 32    	│
│	42755  충청북도 충주시 호암동  221-23  221  23  호암리버빌(1단지)  84.68  201910   15  11000   7  2002  원호암5길 32    	│
│	42756  충청북도 충주시 호암동  221-23  221  23  호암리버빌(1단지)  84.68  201910   17  12000  14  2002  원호암5길 32    	│
│	42757  충청북도 충주시 호암동  221-23  221  23  호암리버빌(1단지)  84.68  201910   26  11200  11  2002  원호암5길 32    	│
│	# df.tail()는 df에서 마지막 5개 행만 출력합니다.																		│
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

2. 열 전체 자료 출력하기
데이터프레임에서 원하는 열의 전체 자료를 보려면 간단하게 다음과 같이 입력하면 됩니다.
┌───────────────────────────────────────────┐
│	>>> df.지역	# '지역'열의 전체 자료를 출력		│
│	0         강원도 강릉시 견소동               	│
│	1         강원도 강릉시 견소동               	│
│	2         강원도 강릉시 견소동               	│
│	3         강원도 강릉시 견소동               	│
│	4         강원도 강릉시 견소동               	│
│	             ...						│
│	42753    충청북도 충주시 호암동              	│
│	42754    충청북도 충주시 호암동              	│
│	42755    충청북도 충주시 호암동              	│
│	42756    충청북도 충주시 호암동              	│
│	42757    충청북도 충주시 호암동              	│
│	Name: 지역, Length: 42758, dtype: object	│
└───────────────────────────────────────────┘

3. 조건별로 출력하기
자료가 너무 많아서 어떤 조건에 해당하는 것만 보고 싶다면 다음과 같이 조건문을 추가하면 됩니다. 어떻게 판다스는 넘파이와 마찬가지로 매우 직관적인 해법을 제시합니다.
┌───────────────────────────────────────────────────────────────────────────────┐
│	>>> df.면적 > 130       # 면적이 130을 넘는 값은 True, 아니면 False로 나눠서 보여줍니다.	│
│	0        False																│
│	1        False																│
│	2        False																│
│	3        False																│
│	4        False																│
│	         ...  																│
│	42753    False																│
│	42754    False																│
│	42755    False																│
│	42756    False																│
│	42757    False																│
│	Name: 면적, Length: 42758, dtype: bool										│
└───────────────────────────────────────────────────────────────────────────────┘

면적이 130㎡을 넘는 아파트의 가격만 보고 싶은 경우에는 다음과  같이 명력합니다.
┌───────────────────────────────────────────┐
│	>>> df.가격[df.면적 > 130] 				│
│	6        34300							│
│	39       21000							│
│	334      29500							│
│	433      26000							│
│	434      24000							│
│	         ...  							│
│	42595    15000							│
│	42607    18500							│
│	42663    31500							│
│	42736    18500							│
│	42737    16200							│
│	Name: 가격, Length: 1567, dtype: int64	│
└───────────────────────────────────────────┘

조금 더 조건을 추가해 볼까요? 면적은 130㎡이 넘고 가격은 2억 원 미만만 출력하라는 명령을 할 수 있습니다. 이때 조건을 괄호로 묶고 기호 '&'(and)를 써줍니다.
┌───────────────────────────────────────────────────┐
│	>>> df.가격[(df.면적 > 130) & (df.가격 < 15000)]	│
│	862      14900									│
│	927      13800									│
│	16785    14700									│
│	36733    14700									│
│	37726    13700									│
│	38811    14600									│
│	39487    12000									│
│	40680    12500									│
│	41173    14000									│
│	41578    13000									│
│	Name: 가격, dtype: int64							│
└───────────────────────────────────────────────────┘

두 가지 조건을 모두 충족시키는 경우는 열 개밖에 없는 것을 확인할 수 있습니다.

두 두기 조건 중 하나라도 만족하면 결괏값을 반환하라는 명령을 할 수 있습니다. 이럴 때는 기호 '|'(or)를 써 줍니다.
┌───────────────────────────────────────────────────────────────────────┐
│	>>> df.가격[(df.면적 > 130) | (df.가격 < 15000)]						│
│	0        10900														│
│	6        34300														│
│	35        4600														│
│	36       13200														│
│	37       14700														│
│	         ...  														│
│	42753     7000														│
│	42754    12000														│
│	42755    11000														│
│	42756    12000														│
│	42757    11200														│
│	Name: 가격, Length: 11499, dtype: int64	# length 값이 11499 입니다.	│
└───────────────────────────────────────────────────────────────────────┘

Length 값을 보면 면적이 130㎡보다 넓거나 가격이 2억 원 미만인 아파트는 11499개 있는 것을 알 수 있습니다.

4. 원하는 자료만 살펴보기
데이터프레임에서 값을 선택할 때 더 정교하게 조건을 추가하고 싶다면 loc을 사용합니다.
┌───────────────────────────────────────┐
│	df.loc[원하는 행의 조건, 원하는 열의 조건]	│
└───────────────────────────────────────┘

예를 들어 데이터프레임이 df로 정의되어 있고 '아파트', '가격'만 10번까지만 출력하고 싶다면 다음과 같이 명령할 수 있습니다. 실습 과정으 그대로 따라왔다면 가음과 같이 실행됩니다.
┌───────────────────────────────────────┐
│	>>> df.loc[:10, ['아파트', '가격']]	│
│	# '아파트'와 '가격'자료만 10번까지 출력합니다,	│
│	                아파트     가격		│
│	0              송정한신  10900			│
│	1              송정한신  18500     	│
│	2      송정해변신도브래뉴아파트  25000  	│
│	3      송정해변신도브래뉴아파트  20600  	│
│	4      송정해변신도브래뉴아파트  20500  	│
│	5   강릉 교동 풍림아이원 아파트  29200  	│
│	6       강릉교동롯데캐슬1단지  34300  		│
│	7       강릉교동롯데캐슬2단지  32500  		│
│	8             교동1주공  16200     	│
│	9             교동1주공  21550     	│
│	10            교동1주공  21800     	│
└───────────────────────────────────────┘

이번에는 4억 원을 초과하는 가격으로 거래된 아파트만 한번 출력해 보겠습니다.
┌───────────────────────────────────────────────────────────────┐
│	>>> df.loc[:, ['아파트', '가격']][df.가격 > 40000]				│
│	# [df.가격 > 40000]와 같이 조건문을 추가하면 조건을 만족하는 내용만 출력	│
│	                  아파트     가격								│
│	382          속초청호아이파크  45800								│
│	541          무실e-편한세상  44600								│
│	592          원주반곡아이파크  40700								│
│	842    온의 롯데캐슬 스카이클래스  44000							│
│	843    온의 롯데캐슬 스카이클래스  42900							│
│	...               ...    ...								│
│	42364       신영지웰시티 1차  47700								│
│	42365       신영지웰시티 1차  46000								│
│	42366       신영지웰시티 1차  55800								│
│	42367       신영지웰시티 1차  67000								│
│	42424          봉명아이파크  49000								│
└───────────────────────────────────────────────────────────────┘

이처럼 loc까지 사용하면 자신이 원하는 조건에 맞는 데이트를 마음껏 불러낼 수 있스빈다. 계속 연습하다 보면 아무리 큰 데이터가 있어도 입맛에 맞는 데이터만 뽑아볼 수 있겠죠?

5. 새로운 값 추가하기
이번에는 새로운 열과 값을 추가하는 방법을 알아보겠습니다. 먼저 새로운 열을 추가하는 방법은 매우 간단합니다.
┌───────────────────────────────────┐
│	df['새로운 열 이름'] = 넣고 싶은 값	│
└───────────────────────────────────┘

여기에서는 면적 대비 가격을 알아보겠습니다. 이 값을 흔히 제곱미터(㎡)당 가격이라고 일컫는데, 쉽게 표현하기 위해서 '단가'라고 이름을 정하겠습니다.
┌───────────────────────────────────────────────────────────┐
│	>>> df['단가'] = df.가격 / df.면적 							│
│	# 면적 대비 가격을 '단가'라는 변수 이름으로 저장					│
│	>>> df.loc[:10, ('가격', '면적', '단가')]					│
│	# loc 문으로 '가격', '면적', '단가' 세 가지 변수의 값을 10번까지 출력	│
│	       가격        면적          단가						│
│	0   10900   59.8000  182.274247							│
│	1   18500  116.1750  159.242522							│
│	2   25000   84.9900  294.152253							│
│	3   20600   84.9900  242.381457							│
│	4   20500   84.9900  241.204848							│
│	5   29200   84.9964  343.543962							│
│	6   34300  135.1727  253.749463							│
│	7   32500  118.0686  275.263703							│
│	8   16200   59.8900  270.495909							│
│	9   21550   84.8400  254.007544							│
│	10  21800   84.8400  256.954267							│
└───────────────────────────────────────────────────────────┘

6. 데이터 정렬하기
이번에는 데이터를 정렬하는 방법에 대해서 알아보겠습니다. 숫자가 작은 것부터 큰 적으로 정렬하는 방법을 오름차순, 반대의 경우를 내림차순이라고 합니다. 엑셀에서 데이터를 오름차순 혹은 내림차순으로 정렬해 본 적 있지요? 엑셀에서도 가장 많이 쓰는 기능 중 하나일 텐데요. 파이썬에서는 별다른 조건을 주지 않으면 오름차순으로 정렬합니다.

인덱스에 따라서 정렬하는 명령어는 sort_values입니다. 특정한 열을 조건에 맞춰서 정렬하고 싶다면 다음과 같이 명령어를 써주면 됩니다.
┌───────────────────────────────────────────────────────────────┐
│	df.sort_values(by = '열 이름')					# 오름차순 정렬	│
│	df.sort_values(by = '열 이름', ascending = False)	# 내림차순 정렬	│
└───────────────────────────────────────────────────────────────┘

먼저 가격을 기준으로 오름차순으로 정렬해 보겠습니다.
┌───────────────────────────────────────────────────────────────────────────┐
│	>>> df.sort_values(by = '가격').loc[:, ('가격', '지역')] 					│
│	# 가격이 가장 싼 아파트부터 가격과 지역만 출력										│
│	           가격                지역										│
│	17024     600      경상북도 구미시 원평동										│
│	17022     700      경상북도 구미시 원평동										│
│	17637     750  경상북도 칠곡군 약목면 관호리										│
│	17031     800      경상북도 구미시 원평동										│
│	17027     800      경상북도 구미시 원평동										│
│	...       ...               ...    										│
│	27036  373000     서울특별시 강남구 대치동										│
│	26805  376640     부산광역시 해운대구 우동										│
│	29946  415000     서울특별시 서초구 반포동										│
│	27061  461000     서울특별시 강남구 도곡동										│
│	31258  485000     서울특별시 용산구 한남동										│
│																			│
│	[42758 rows x 2 columns]												│
│	>>> df.sort_values(by = '가격', ascending = False).loc[:, ('가격', '지역')]	│
│	# 내림차순으로 다시 정렬														│
│	           가격                지역										│
│	31258  485000     서울특별시 용산구 한남동										│
│	27061  461000     서울특별시 강남구 도곡동										│
│	29946  415000     서울특별시 서초구 반포동										│
│	26805  376640     부산광역시 해운대구 우동										│
│	27036  373000     서울특별시 강남구 대치동										│
│	...       ...               ...    										│
│	17027     800      경상북도 구미시 원평동										│
│	17025     800      경상북도 구미시 원평동										│
│	17637     750  경상북도 칠곡군 약목면 관호리										│
│	17022     700      경상북도 구미시 원평동										│
│	17024     600      경상북도 구미시 원평동										│
│																			│
│	[42758 rows x 2 columns]												│
└───────────────────────────────────────────────────────────────────────────┘

조금 응용을 해 볼까요? 4억이 넘는 아파트를 면적이 넓어지는 순서, 즉 오름차순으로 정렬하고 '가격', '면적', '지역'을 추가해 보겠습니다. 이렇게 단순한 조건을 복잡하게 바꿔가면서 연습해 보는 것이 코딩 실력을 향상시키는 데 도움이 됩니다.
┌───────────────────────────────────────────────────────────────────────────────┐
│	>>> df[df.가격 > 40000].sort_values(by = '면적').loc[:, ('가격', '면적', '지역')]	│
│	# df.가격 > 40000 : 4억이 넘는 집만 먼저 추출										│
│	# df[df.가격 > 40000].sort_values(by = '면적') : 면적 기준으로 정렬					│
│	# 정렬한 데이터 프레임에서 '가격', '면적', '지역' 정보만 추출								│
│	           가격        면적               지역									│
│	30111   90000   25.3284  서울특별시 성동구 성수동1가								│
│	27124   74000   28.2460    서울특별시 강남구 역삼동								│
│	27122   74500   28.2460    서울특별시 강남구 역삼동								│
│	27123   76000   28.2460    서울특별시 강남구 역삼동								│
│	29725   43500   30.0100    서울특별시 마포구 아현동								│
│	...       ...       ...              ...									│
│	27118  245000  242.8200    서울특별시 강남구 역삼동								│
│	30002  206000  244.4200    서울특별시 서초구 서초동								│
│	10106  100000  244.6630    경기도 용인수지구 성복동								│
│	31501  240000  273.8200     서울특별시 중구 신당동									│
│	35826  300000  291.3360    인천광역시 연수구 송도동								│
│																				│
│	[10486 rows x 3 columns]													│
└───────────────────────────────────────────────────────────────────────────────┘

7. 문자열 다루기
판다스에서도 문자열을 다루는 방법이 있습니다. 바로 str 매서드를 사용하는 것입니다. 여기에서는 그중 간단한 방법 하나만 살펴보고 넘어가겠습니다.

str.find()를 사용하면 특정한 문자를 포함하는 열을 추출할 수 있습니다. 사용법은 다음과 같습니다.
┌───────────────────────────────────┐
│	df.검색할 열.str.find('찾는 문자열')	│
└───────────────────────────────────┘

이 명령은 찾아야 하는 문자열의 유무가 아닌 문자열의 '인덱스'즉, 문자열이 어디에 있는지를 찾아서 반환하는 특이한 구조를 가지고 있스빈다. 만약 해당 열에서 찾는 문자열이 없다면 -1을 반환합니다.

예를 들어 df에 저장된 아파트 실거래가에서 강릉시 자료만 고라내고 싶습니다. 먼저 이 작업을 하기 전에 데이터가 어떻게 생겼는지 head()를 통해서 다시 한번 확인해 보겠습니다.
┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│	>>> df.head()																											│
│	            지역   번지   본번  부번           아파트       면적    계약년월  계약일     가격   층  건축년도           도로명          단가	│
│	0  강원도 강릉시 견소동  202  202   0          송정한신   59.800  201910    4  10900   5  1997   경강로2539번길 8  182.274247		│
│	1  강원도 강릉시 견소동  202  202   0          송정한신  116.175  201910   31  18500  10  1997   경강로2539번길 8  159.242522		│
│	2  강원도 강릉시 견소동  289  289   0  송정해변신도브래뉴아파트   84.990  201910    5  25000   6  2005  경강로2539번길 22  294.152253	│
│	3  강원도 강릉시 견소동  289  289   0  송정해변신도브래뉴아파트   84.990  201910   12  20600   3  2005  경강로2539번길 22  242.381457	│
│	4  강원도 강릉시 견소동  289  289   0  송정해변신도브래뉴아파트   84.990  201910   20  20500   1  2005  경강로2539번길 22  241.204848	│
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

강릉시 자료만 골라내려면 '지역'열에서 '강릉'이라는 단어가 있는 열을 찾으면 되겠네요. 다음과 같이 입력해 보겠스빈다.
┌───────────────────────────────────────────────────────────────────────────┐
│	>>> df.지역.str.find('강릉')												│
│	0        4					# 다섯 번째 문자열에서 '강릉'을 찾아 인덱스 값 4를 출력	│
│	1        4																│
│	2        4																│
│	3        4																│
│	4        4																│
│	        ..																│
│	42753   -1					# 찾지 못했으면 -1을 출력							│
│	42754   -1																│
│	42755   -1																│
│	42756   -1																│
│	42757   -1																│
│	Name: 지역, Length: 42758, dtype: int64									│
└───────────────────────────────────────────────────────────────────────────┘

찾는 문자열이 없을 때 -1을 반환하는 점을 활용하면 다음과 같이 원하는 자료만 골라 새 데이터프레임을 만들 수 있습니다.
┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│	>>> df[df.지역.str.find('강릉') > -1]																							│
│	# 지역에 '강릉'이 들어간 자료만 따로 모아 데이터프레임으로 출력																				│
│	              지역   번지   본번  부번           아파트        면적    계약년월  계약일     가격   층  건축년도           도로명          단가	│
│	0    강원도 강릉시 견소동  202  202   0          송정한신   59.8000  201910    4  10900   5  1997   경강로2539번길 8  182.274247		│
│	1    강원도 강릉시 견소동  202  202   0          송정한신  116.1750  201910   31  18500  10  1997   경강로2539번길 8  159.242522		│
│	2    강원도 강릉시 견소동  289  289   0  송정해변신도브래뉴아파트   84.9900  201910    5  25000   6  2005  경강로2539번길 22  294.152253		│
│	3    강원도 강릉시 견소동  289  289   0  송정해변신도브래뉴아파트   84.9900  201910   12  20600   3  2005  경강로2539번길 22  242.381457		│
│	4    강원도 강릉시 견소동  289  289   0  송정해변신도브래뉴아파트   84.9900  201910   20  20500   1  2005  경강로2539번길 22  241.204848		│
│	..           ...  ...  ...  ..           ...       ...     ...  ...    ...  ..   ...           ...         ...				│
│	183  강원도 강릉시 회산동  608  608   0  강릉서희스타힐스리버파크   84.8956  201910   24  24000  10  2017       회산로 344  282.700163		│
│	184  강원도 강릉시 회산동  130  130   0      힐스테이트 강릉   84.9925  201910    7  24000   3  2018   회산로383번길 37  282.377857		│
│	185  강원도 강릉시 회산동  130  130   0      힐스테이트 강릉   74.9974  201910   19  23000  15  2018   회산로383번길 37  306.677298		│
│	186  강원도 강릉시 회산동  130  130   0      힐스테이트 강릉   74.9985  201910   21  24100   6  2018   회산로383번길 37  321.339760		│
│	187  강원도 강릉시 회산동  130  130   0      힐스테이트 강릉   74.9974  201910   29  25400  13  2018   회산로383번길 37  338.678408		│
│																																│
│	[188 rows x 13 columns]																										│
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

이렇게 따로 추룰한 값을 자주 사용할 것 같으면 별도의 객체로 저장합니다. dtF라는 새 객체에 아ㅠ에서 만든 데이터프레임을 저장해 보겠습니다.
┌───────────────────────────────────────────────────────────────┐
│	>>> dfF = df[df.지역.str.find('강릉') > -1]					│
│	>>> dfF.mean()												│
│	본번               inf										│
│	부번      1.085106e+00										│
│	면적      7.047780e+01										│
│	계약년월    2.019100e+05										│
│	계약일     1.527128e+01										│
│	가격      1.541457e+04										│
│	층       7.420213e+00										│
│	건축년도    2.000463e+03										│
│	단가      2.099422e+02										│
│	dtype: float64												│
│	# dfF 또한 데이터프레임이므로 앞에서 알아본 여러 함수를 사용할 수 있습니다.	│
└───────────────────────────────────────────────────────────────┘

05-5 판다스로 통계 데이터 다루기
지금까지 파낟스가 무엇이고 데이터프레임을 어떻게 살펴보는지 알아봤습니다. 이제 판다스로 통계 데이터 분석을 어떻게 하는지 실습을 통해 알아보겠습니다.

Do it 기초통계량 살펴보기
데이터프레임으로 데이터를 가공하는 이유는 결국 통계 데이터를 분석하기 위해서입니다. 데이터의 분석이 이 책의 주제 전부는 아니지만, 통계 데이터를 다루는 것은 파이썬을 하는 중요한 이유 중 하나이므로 간단히 다뤄 보겠습니다.

가상의 설문 데이터를 저장해 놓은 servey.csv파일을 05장 실습 파일에서 찾아 파치썬 실해경로에 넣으세요. 그리고 survey.csv 파일을 read_csv() 함수로 불러오세요.
┌───────────────────────────────────────────────────────────┐
│	>>> import os, re										│
│	>>> import pandas as pd									│
│	>>> from Function import usercsv						│
│	>>> from Function import Learning as ln					│
│	>>> path = ln.MoveLearningDataDir()						│
│	>>> df2 = pd.read_csv('survey.csv')     # df2 객체에 저장	│
└───────────────────────────────────────────────────────────┘

먼저 이 데이터프레임에 어떤 자료가 들어있는지 확인해 봐야겠지요? head() 함수를 사용해 앞부분만 간단히 출력해 보겠습니다.
┌───────────────────────────────────────────────────┐
│	>>> df2.head()									│
│	  sex  income  English  jobSatisfaction  stress	│
│	0   m    3000      500                5       5	│
│	1   f    4000      600                4       4	│
│	2   f    5000      700                3       2	│
│	3   m    6000      800                2       2	│
│	4   m    4000      700                2       5	│
└───────────────────────────────────────────────────┘

성별(sex), 수입(income), 영어 점수(English), 직업 만족도(jobSatisfaction), 스트레스(stress)가지 총 5개의 열에 대한 지표가 저장되어 있네요. 이제 이 자료를 가지고 간단한 분석을 진행해 보겠습니다.

1. 평균과 합 구하기
먼저 평균과 합을 구해 보겠습니다. 모든 지표의 평균은 mean()함수로 구합니다.
┌───────────────────────────────────┐
│	>>> df2.mean()					│
│	income             4304.217391	│
│	English             608.695652	│
│	jobSatisfaction       3.304348	│
│	stress                3.347826	│
│	dtype: float64					│
└───────────────────────────────────┘

수입의 평균만 구하고 싶다면 다음과 같이 입력합니다.
┌───────────────────────────┐
│	>>> df2.income.mean()	│
│	4304.217391304348		│
└───────────────────────────┘

수입의 합계는 다음과 같이 sum() 함수로 구합니다.
┌───────────────────────────┐
│	>>> df2.income.sum()	│
│	98997					│
└───────────────────────────┘

2. 중앙값 구하기
중앙값(median)은 말 그대로 중앙에 위치한 값입니다. 중앙값을 출력하는 함수는 median()입니다. df2에서 수입의 중앙값을 구하면 다음과 같습니다.
┌───────────────────────────┐
│	>>> df2.income.median()	│
│	4999.0					│
└───────────────────────────┘

3. 기초통계량 요약해서 출력하기
평균이나 중아값을 일일이 구해야 하는 건 번거로은 일이지요. 데이터 분석을 위해 필요한 분산과 표준편차, 최대, 최소 등의 값을 한 번에 출력해서 봐야 그 데이터의 성격을 이해할 수 있습니다. 데이터의 성격을 보여주는 이런 자료를 '기초통계량'이라고 표현합니다. 그래서 논문에서는 통계를 본격적으로 분석하기 전에 기초통계량 정보를 먼저 보여줍니다. 이 데이터가 대략 어헐게 생긴 데이터인지 사용자에게 알려주고 시작하는 것입니다.

데이터프레임의 기초통계량을 보여누는 함수는 describe()입니다. 영어로는 기술하다, 혹은 묘사한다는 뜻입니다. 데이터를 본격적으로 분석하기 전에 이 데이터의 생김새가 어떤지 보여준다는 점에서 잘 맞는 이름 같습니다. 다음과 같이 사용해 봅니다.

┌───────────────────────────────────────────────────────────────────────────────┐
│	>>> df2.describe()															│
│	            income     English  jobSatisfaction     stress					│
│	count    23.000000   23.000000        23.000000  23.000000	# 데이터 개수		│	
│	mean   4304.217391  608.695652         3.304348   3.347826	# 평균			│	
│	std    1019.478341   99.603959         1.258960   1.433644	# 표준편차 		│	
│	min    3000.000000  500.000000         1.000000   1.000000	# 최솟값			│	
│	25%    3000.000000  500.000000         2.500000   2.000000	# 0~25% 값		│
│	50%    4999.000000  600.000000         3.000000   4.000000	# 50% 값(중앙값)	│
│	75%    5000.000000  700.000000         4.000000   5.000000	# 0~75% 값		│
│	max    6000.000000  800.000000         5.000000   5.000000	# 최댓값			│
└───────────────────────────────────────────────────────────────────────────────┘

성별이나 스트레스 점수는 관심이 없고 수입에만 관심이 있다면 다음과 같이 수입의 기초통계량만 출력할 수 있습니다.
┌───────────────────────────────────┐
│	>>> df2.income.describe() 		│
│	count      23.000000			│
│	mean     4304.217391			│
│	std      1019.478341			│
│	min      3000.000000			│
│	25%      3000.000000			│
│	50%      4999.000000			│
│	75%      5000.000000			│
│	max      6000.000000			│
│	Name: income, dtype: float64	│
└───────────────────────────────────┘

Do it 기초통계량 분석하기
1. 빈도 분석하기:value_counts()
빈도(frequency) 분석은 통계를 분석할 때 매우 많이 사용하는 기법입니다. 빈도 분석이란 말 그대로 빈도, 즉 그 변수가 몇 번 나타났는지를 세는 분석입니다. 판다스에서 빈도 분석을 하는 함수는 value_counts()입니다. 기본 사용법은 다음과 같습니다.
┌───────────────────────────┐
│	df.변수.value_counts()	│
└───────────────────────────┘

앞에서 만든 데이터프레임 df2를 활용해 빈도 분석을 해 보겠습니다. 먼저 m(남성)과 f(여성)의 빈도를 알아보곘습니다.
┌───────────────────────────────┐
│	>>> df2.sex.value_counts()	│
│	m    14						│
│	f     9                     │
│	Name: sex, dtype: int64     │
└───────────────────────────────┘
m의 빈도는 14, f의 빈도는 9가 나옵니다. 여기에서는 14명의 남성과 9명의 여성이 설문에 답변을 했다는 의미겠네요.

2. 두 집단 편균 구하기:groupby()
이번에는 남성과 여성으로 집단을 나눠서 데이터를 살펴보곘습니다. 먼저 다시 한번 df2의 기초통계량을 살펴보겠습니다.
┌───────────────────────────────────────────────────────────────┐
│	>>> df2.describe()											│
│	            income     English  jobSatisfaction     stress	│
│	count    23.000000   23.000000        23.000000  23.000000	│
│	mean   4304.217391  608.695652         3.304348   3.347826	│
│	std    1019.478341   99.603959         1.258960   1.433644	│
│	min    3000.000000  500.000000         1.000000   1.000000	│
│	25%    3000.000000  500.000000         2.500000   2.000000	│
│	50%    4999.000000  600.000000         3.000000   4.000000	│
│	75%    5000.000000  700.000000         4.000000   5.000000	│
│	max    6000.000000  800.000000         5.000000   5.000000	│
└───────────────────────────────────────────────────────────────┘

이 설문 조사의 모집단은 직업 만족도(3.30)보다 스트레스(3.34)가 조금 더 높네요. 남성과 여성의 직업 만족도와 스트레스는 각각 어떻게 나타날까요?

다음과 같이 입력된 데이터프레임에서 groupby() 함수로 이런 문제의 해답을 구할 수 있습니다. 사용법은 다음과 같습니다.
┌───────────────────────────────────┐
│	df.groupby(그룹을 나누는 변수).연산	│
└───────────────────────────────────┘

예를 들어 데이터프레임에서 남성(m)과 여성(f)으로 데이터(df2.sex)를 구분한 다음(groupby) 평균(mean)을 구하고 싶다면 다음과 같이 입력하면 됩니다.
┌───────────────────────────────────────────────────────────┐
│	>>> df2.groupby(df2.sex).mean()							│
│	# df2.groupby(by = 'sex').mean()으로 명령해도 됩니다.			│
│	          income     English  jobSatisfaction    stress	│
│	sex														│
│	f    4333.111111  633.333333         3.666667  3.111111	│
│	m    4285.642857  592.857143         3.071429  3.500000	│	
└───────────────────────────────────────────────────────────┘

여성의 평균 수입은 4,333만 원, 남성의 평균 수입은 4,285만 원으로 나옵니다. 마찬가지로 영어 점수, 직업 만족도, 스트레스에 대해서도 평균을 비교해 볼 수 있습니다.

그런데 통계에 대한 지식이 있다면, 곧바로 '여성이 남성보다 임금이 높다'고 말하기 어렵다는 것을 알 것입니다. 두 집단이 유의한(significant) 평균 차이가 나는지 검증해야 하기 때문입니다.

05-6 실전 통계 분석 맛보기
조금 더 의미 있는 통계 분석을 하고 싶을 때는 어떻게 해야 할까요? 저는 대학원을 다닐 때 사회과학 계열 논문을 읽으면서 수많은 설문 데이터를 분석한 결과물을 이해해야 할 필요를 느꼈습니다. 또한 요즘은 여러 분야에 빅데이터를 쌓이면서 분야와 직군을 가리지 않고 데이터분석 능력이 필요한 시대가 왔지요.

사회과학 방법론 등을 전문적으로 공부해 보지 않은 사람이 처음부터 통계 이론을 공부하고 이해해서 직접 수식을 함수로 만들려면 너무 오랜 시간이 걸립니다. 이럴 때 가장 좋은 방법은 간단한 데이터 분석을 실제로 해 보는 것 입니다. t검정, 유의 수준, 회귀 분석 등 기초 개념만 알고 직접 데이터 분석을 하다 보면 나중에 복잡한 데이터 분석 자료를 읽을 때 큰 도움이 됩니다.

이제부터는 넘파이나 판다스말고 다른 패키지도 필요합니다. 다른 패키지의 함수를 사요하면 복잡한 데이터 지표도 쉽게 계산할 수 있습니다. 복잡한 계산은 컴퓨터에 맡기고 우리는 결괏값을 해석하는 능력을 키우면 됩니다.

Do it 싸이파이 패키지로 t검정 하기
먼저 앞에서 사용한 설문조사 결과를 둘로 나눠 각각의 평균을 비교하고, 차이가 있다면 그 차이가 유의한지 알아보겠습니다. 독룁된 두 집단의 평균을 비교하는 가장 간편한 데이터 분석 방법은 t검정 입니다.
% t검정 등 통계 분석 방법의 기본 원리를 이해하려면 여러 기초 통계 개념을 알아야 하지만, 이 장에서는 파이썬 패키지로 어떻게 데이터 분석을 하는지만 간단히 알아봅니다.
% 알아두면 좋아요. t검정이란?
t검정이란 두 집단의 분산을 알 수 없을 때 두 집단이 t분포를 따른다고 가정하고 평균 등을 비교한는 통계 검정 방법을 의미합니다. 실제로 두 집단의 평균을 비교할 때 많이 사용하는 방법입니다.

1. 싸이파이(SciPy)라는 패키지의 모듈을 사용하면 t검정을 쉽게 할 수 있습니다. 싸이파이 패키지는 파이썬을 기반으로 한 수치 분석, 연산, 엔지니어링 등에 사용됩니다. 넘파이, 판다스, 맷플롯립 등과 함께 빠지지 않고 사용되는 패키지가 바로 이 싸이파이입니다. 싸이파이에서 가장 ㅁ낳이 사용되는 모듈은 통계 관련 함수를 많이 포함한 stats 모듈입니다. 여기에서는 싸이파이 패키지에서 stats 모듈만 임포트 해 사용하겠습니다.
┌───────────────────────────────────────────┐
│	>>> from scipy import stats				│
│	# scipy 패키지에서 stats 모듈만 임포트 합니다.	│
└───────────────────────────────────────────┘

설문 조사 결과를 남성의 수입과 여성의 수입, 이렇게 두 집단으로 나눠 각각 다른 객체에 저장하겠습니다.
┌───────────────────────────────────────────────────────┐
│	>>> male = df2.income[df2.sex == 'm']	# 남성의 수입	│
│	>>> female = df2.income[df2.sex == 'f']	# 여성의 수입	│
└───────────────────────────────────────────────────────┘

stats 모듈의 ttest_ind() 함수를 사용하면 t검정을 쉽게 할 수 있습니다. 변수를 여러개 넣을 수 있지만 여기에서는 다음과 같이 앞에서 만든 두 객체만 넣어 보겠스빈다.
┌───────────────────────────────────────────────────────────────────────────────┐
│	>>> stats.ttest_ind(male, female) 											│
│	Ttest_indResult(statistic=-0.10650308143428425, pvalue=0.9161940781163369)	│
└───────────────────────────────────────────────────────────────────────────────┘

두가지 값이 출력됩니다. 여기에서는 두 값 중 pvalue에 대해서만 알아보겠습니다.

2. pvalue는 유의확률(p-value)을 의미합니다. 유의확률은 간단하게 말하자면, 유의확률 값이 작을수록 유의한 차이가 있다고 해석하면 됩니다. 일반적으로 95% 또는 99%를 유의한 확률의 기준으로 삼기 때문에 유의확률 값이 0.05 미난이거나 0.01 미만이면 유의한 차이가 나타난다고 말할 수 있습니다. 이 결과에서 pvalue는 0.916으로 1에 가까울 정도로 높습니다. 즉, 남성과 여성의 수입 평균을 비교한 t검정의 결과에 유의한 차이가 있다고 보기는 어렵습니다.

ttest_result라는 별도의 객체를 만들어서 t검정의 결괏값을 저장합니다.
┌───────────────────────────────────────────────────────────────────────────────┐
│	>>> ttest_result = stats.ttest_ind(male, female)							│
│	# 아까와 같이 명령하고 그 결과를 객체로 저장											│
│	>>> print(ttest_result)														│
│	Ttest_indResult(statistic=-0.10650308143428425, pvalue=0.9161940781163369)	│
│	# 객체를 출력시키면 아까와 같은 결과를 얻을 수 있음										│
└───────────────────────────────────────────────────────────────────────────────┘

ttest_result의 인덱스 0에는 statistic 값이 들어가고, 인덱스 1에는 pvalue 값이 들어갑니다.
┌───────────────────────────────┐
│	>>> print(ttest_result[0]) 	│
│	-0.10650308143428425		│
│	>>> print(ttest_result[1]) 	│
│	0.9161940781163369			│
└───────────────────────────────┘

유의확률, 즉 pvalue가 0.05보다 작은 경우에만 유의하다고 판정하겠습니다. 이와 같은 조건문을 다음과 같이 넣을 수도 있습니다.
┌───────────────────────────────────────────────────────────────────────────┐
│	>>> if ttest_result[1] > .05:											│
│			print('p-value는 %f로 95% 수준에서 유의하지 않음' % ttest_result[1])	│
│		else:																│
│			print('p-value는 %f로 95% 수준에서 유의gka' % ttest_result[1])		│
│	# 유의확률이 0.05보다 작거나 같으면 95% 수준에서 유의한 것으로 판정						│
│	p-value는 0.91619로 95% 수준에서 유의하지 않음									│
│	# 이 결과는 이미 확인한 것처럼 유의하지 않음										│
└───────────────────────────────────────────────────────────────────────────┘

피어슨과 스피어만 상관관계 분석 알아보기

상관관계(correlation) 분석은 두 변수가 얼마나 관계가 있는지 알아보는 방법입니다. 두 수치가 모두 숫자로 이뤄져 있다고 했을 때 두 변수 사이에 여러 관계가 관찰될 수 있습니다. 상관관계를 분석하는 방법은 크게 피어슨(Pearson), 스피어만(Spearman)으로 나눌 수 있습니다. 상관관계 분석 결과로 도출되는 값을 '상관계수'(r)는 -1부터 1까지 범위를 가집니다.



스피어만 상관계수는 변수가 순위 척도(ordinal scale)일 때 사용합니다. 변수가 각각 어떤 값을 가지는 경우가 아니라 어떤 순위로 이뤄져 있을 수도 있습니다. 예를 들어 어떤 고등학교의 3학년 모의 고사 성적을 과목별로 등수를 매겼을 때 국어 영역의 등수와 수리 영역의 등수가 어떤 상관관계가 있는지 스피어만의 상관관계로 알아볼 수 있습니다. 이때 '점수'가 아니라 '순위'라는 점이 스피어만 상관계수의 특징이라고 말할 수 있습니다.

보통 상관계수라고 하면, 피어슨 상관관계를 의미하는 경우가 대부분입니다. 피어슨의 상관관계수는 순위가 아니라 연속형 자료(continuous data: 점수, 키, 성적 따위의 연속되는 숫자를 가진 자료)의 상관관계를 다룹니다.

예를 들어 기온과 아이스크림 판매량이라는 두 개의 변수가 있다고 가정해 보겠습니다. 아마도 기온이 올라갈수록 아이스크림이 잘 팔릴 가능성도 커지겠지요? 두 변수의 분포를 그래프로 그려서 다음과 같이 우상향하는 곡선이 그려진다면 두 변수의 상관계수 값은 1에 가까워집니다.

이와 반대로, 사과가 많이 파리면 귤이 안 팔리고, 귤이 많이 팔리면 사과가 안 팔리는 관계가 성립할 수 있습니다. 이렇게 두 변수의 방향이 거꾸로 움직일 때 상관관계수는 -1에 가까워집니다.

마지막으로 신발 판매량과 우산 판매량의 관계를 생각해 볼까요? 아마 큰 관계가 없을 것 같네요. 정말 두 변수 사이에 관계가 없다면 두 변수의 '임의(random)' 분포한다고 표현하고, 상관계수는 0에 가깝게 나옵니다.

상관관계 역시 계수만 보면 됩는 것이 아니라 실제 통계 분석에서는 유의확률(p-value, 파이썬 출력에서는 pvalue)를 보아야 합니다. t검정에서와 마찬가지로 유의확률이 0.05보다 작을 때는 95% 수준에서 유의하고, 0.01보다 작으면 99% 수준에서 유의하다고 말할 수 있습니다.

자, 이제 설문 조사의 여러 변수 수이의 상관관계를 분석해 보겠습니다. 앞에서처럼 일일이 점을 찍어서 그래프를 그리려면 오랜 시간이 걸리곘지요? 걱정하지 마세요. 상관관계 분석도 앞에서 했던 t검정과 마찬가지로 파이썬 패키지의 함수를 사용하면 쉽게 구할 수 있습니다.

Do it 두 변수의 상관관계 분석하기

1. 판다스 패키지에 있는 corr() 함수를 사용하면 쉽게 상관관계 분석이 가능합니다. corr() 함수의 사용 방법은 다음과 같습니다. 기본 분석 방법은 피어슨 분석이며, 스피어만 분석을 실행하고 싶다면 다음과 같이 method = 'spearman'을 추가하면 됩니다.
┌───────────────────────────────────────────────────────────────────────────────────────────────────┐
│	>>> df.corr()	# 피어슨 상관관계 분석 결과를 출력합니다.													│
│	<stdin>:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. 	│
│	In a future version, it will default to False. 													│	
│	Select only valid 	columns or specify the value of numeric_only to silence this warning.		│	
│			부번			면적			계약년월		계약일        가격			층			건축년도			│	
│	부번		 1.000000	-0.027697	NaN			 0.003147	-0.028820	-0.030163	-0.042525		│
│	면적		-0.027697	 1.000000	NaN			-0.030011	 0.458365	 0.174216	 0.232155		│
│	계약년월	NaN   		NaN			NaN			NaN			NaN      	NaN			NaN				│	
│	계약일	 0.003147	-0.030011	NaN			 1.000000	-0.084614	 0.003314	 0.017725		│
│	가격		-0.028820	 0.458365	NaN			-0.084614	 1.000000	 0.201469	 0.211600		│
│	층		-0.030163	 0.174216	NaN			 0.003314	 0.201469	 1.000000	 0.307520		│
│	건축년도	-0.042525	 0.232155	NaN			 0.017725	 0.211600	 0.307520	 1.000000		│
│	# 모든 수치형 변수에 ㅔ대해 상관관계가 구해진 것을 확인할 수 있습니다.												│
│																									│
│	>>> df.corr(method = 'spearman') # 스피어만 상관관계 분석 결과를 출력합니다.								│
│	# 스피어만의 순서형 상관관계의 방법을 채택하고 싶으면 'spearman'을 지정합니다.										│
│	<stdin>:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. 	│
│	In a future version, it will default to False. 													│
│	Select only valid columns or specify the value of numeric_only to silence this warning.			│
│			부번			면적			계약년월		계약일		가격			층			건축년도			│
│	부번		 1.000000	-0.144053   NaN			-0.000565	-0.232897	-0.090734	-0.219684		│
│	면적		-0.144053	 1.000000   NaN			-0.032524	 0.542482	 0.169703	 0.319950		│
│	계약년월	NaN			NaN			NaN			NaN			NaN      	NaN      	NaN				│
│	계약일	-0.000565	-0.032524   NaN			 1.000000	-0.073326	-0.001487	 0.019923		│
│	가격		-0.232897	 0.542482   NaN			-0.073326	 1.000000	 0.234934	 0.370053		│
│	층		-0.090734	 0.169703   NaN			-0.001487	 0.234934	 1.000000	 0.283469		│
│	건축년도	-0.219684	 0.319950   NaN			 0.019923	 0.370053	 0.283469	 1.000000		│
└───────────────────────────────────────────────────────────────────────────────────────────────────┘

2. 이와 같은 방법으로 상관관계를 모두 구할 수 있습니다. 그런데 특정 두 변수의 관계만 보고 싶을 수 있습니다. 예를 들어 수입(income)과 스트레스(stress)의 상관관계만 보고 싶다면 다음과 같이 명령하면 됩니다.
┌───────────────────────────────────────┐
│	>>> df2.income.corr(df2.stress) 	│
│	-0.13791959796123449				│
└───────────────────────────────────────┘

자 그러면 income과 stress의 상관관계 값이 -0.13791959796123449가 반환됨을 확인할 수 있습니다.

3. 데이터프레임으로 된 분석 결과를 CSV 파일로 저장하려면 to_csv()함수를 사용합니다. 방법은 다음과 같습니다.
┌───────────────────────────┐
│	df.to_csv('파일 이름')		│
└───────────────────────────┘

앞에서 구한 상관관계 값을 저장한 corr객체를 csv파일로 저장하겠습니다.
┌───────────────────────────────────────────┐
│	>>> corr.to_csv('corr.csv')				│
│	# corr에 저장한 값을 corr.csv 파일로 저장합니다.	│
└───────────────────────────────────────────┘

여기까지 내용을 살펴보면 상관관계는 매우 쉽게 구할 수 있습니다.
% 눈치가 빠른 사람이라면 중요한 값이 빠졌다는 걸 알 수 있습니다. 바로 유의확률입니다. 유의확률이 0.05나 0.01보다 낮아야 상관계수도 의미를 갖습니다. 안타깝게도 판다스의 corr 메서드로는 유의확률을 구할 수 없습니다.

회귀 분석 알아보기
이번에는 회귀 분석에 대해 알아보겠습니다. 회귀 분석(regression)은 통계학의 '꽃'이라고 부를 수 있을만큼 중요한 분석입니다. 회귀 분석을 사용하면 상관관계 분석에서는 파악할 수 없던 두 변수 사이의 인과관계를 파악할 수 있습니다.

회귀 분석의 기본식은 1차 방정식으로 다음과 같이 표현됩니다.
┌───────────────────────────────────────────────┐
│	y = a + bx + c # c는 오차(error)를 의미합니다.	│
└───────────────────────────────────────────────┘
조금 쉽게 이야기하자면 y라는 결과는 x라는 변수에 의해서 설명될 수 있다는 분석입니다. 예를 들어 영어 성적과 직업 만족도의 관계를 살핀다고 하면, 직업 만족도(jobSatisfaction)가 결과(y)가 되고, 영어 성적(English)이 원인이 됩니다. 이렇게 원인이 되는 독립 변수가 하나, 결과가 되는 종속 변수가 하나인 회귀 분석을 단순 회귀 모델(simple regression model), 종속 변수는 하나인데 독립 변수가 여러 개인 모델을 다중 회귀 모델(multiple regression model)이라고 합니다.

Do it! statsmodels 패키지로 회귀 분석하기
이번에는 다음 상활을 가정하고 회귀 분석을 실습해 보겠습니다.

이런 상황이라면?
영어 점수와 직업 만족도 사이에 인과관계가 있는지 분석해 보자.
영어를 잘하면 회사에서 일을 더 수월하게 할 수 있으니 직업 만족도가 높을 것 같습니다. 그런데 정말 그럴까요? 가상의 질문 데이터를 활용해 영어 점수와 직업 만족도 사이에 인과관계가 있는지 회귀 분석을 통해 알아보겠습니다.

1. statsmodels 패키지 임포트 하기
먼저 회귀 분석을 하기 위해 필요한 statsmodels(스테이츠모델즈) 패키지를 임포트 하겠습니다. 이 패키지는 아나콘다와 함께 기본으로 설치되므로 바로 임포트 할 수 있습니다. statsmodels 패키지에는 여러 함수가 있고, 그중에서 회귀 분석 모델을 적용할 수 있는 formula.api만 임포트 해서 사용할 것입니다.
% 임포트 되지 않는다면 pip를 이용해서 statsmodels를 따로 설치하면 됩니다.
┌───────────────────────────────────────────────┐
│	>>> import statsmodels.formula.api as smf	│
│	# 패키지를 편하게 쓰기 위해 smf로 줄여서 임포트			│
└───────────────────────────────────────────────┘

패키지 안에 있는 ols()함수를 사용하면 회귀 분석을 사용할 수 있습니다. ols() 함수의 사용 방법은 다음과 같습니다.
┌───────────────────────────────────────────────────────┐
│	ols(formula = '종속 변수 ~ 독립 변수', data = 데이터프레임)	│
│	# 따움표 위치('종속 변수 ~ 독립 변수')에 유의하세요				│
└───────────────────────────────────────────────────────┘

데이터 프레임 df2에 회귀 분석 모델을 적용해 model객체에 저장합니다. 그리고 회귀 분석 모델의 결괏값을 편하게 출력하기 위해 fit()함수를 사용해 model 객체에서 결괏값을 가져와 result 객체에 저장합니다.
┌───────────────────────────────────────────────────────────────────────────┐
│	>>> model = smf.ols(formula = 'jobSatisfaction~English', data = df2)	│
│	# 종속 변수로 직업 만족도, 독립 변수로 영어 성적을 입력했습니다.							│
│	>>> result = model.fit()												│
│	# 이렇게 결괏값을 따로 저장하는 것이 좋습니다.										│
└───────────────────────────────────────────────────────────────────────────┘

2. 회귀 분석 결과 확인하기
result 객체에 저장한 회귀 분석 모델의 결괏값을 출력하려면 다음과 같이 print(result.sumarry())라고 명령하면 됩니다.
┌───────────────────────────────────────────────────────────────────────────────────────────────┐
│	>>> print(result.summary())																	│
│								OLS Regression Results											│
│	==============================================================================				│
│	Dep. Variable:        jobSatisfaction   <R-squared:                       0.097>			│
│	Model:                            OLS   Adj. R-squared:                  0.054				│
│	Method:                 Least Squares   F-statistic:                     2.266				│
│	Date:                Thu, 29 Dec 2022   <Prob (F-statistic):              0.147>			│
│	Time:                        17:52:06   Log-Likelihood:                -36.243				│
│	No. Observations:                  23   AIC:                             76.49				│
│	Df Residuals:                      21   BIC:                             78.76				│
│	Df Model:                           1				                                        │
│	Covariance Type:            nonrobust				                                        │
│	==============================================================================				│
│				   <coef>    std err          t      P>|t|      [0.025      0.975]				│
│	------------------------------------------------------------------------------				│
│	Intercept      5.7052      1.615      3.532      0.002       2.346       9.065				│
│	<English       -0.0039>    0.003     -1.505      0.147      -0.009       0.002				│
│	==============================================================================				│
│	Omnibus:                        0.120   Durbin-Watson:                   0.777				│
│	<Prob(Omnibus):                 0.942>  Jarque-Bera (JB):                0.306				│
│	Skew:                          -0.126   Prob(JB):                        0.858				│
│	Kurtosis:                       2.495   Cond. No.                     3.90e+03				│
│	==============================================================================				│
│																								│
│	Notes:																						│
│	[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.	│
│	[2] The condition number is large, 3.9e+03. This might indicate that there are				│
│	strong multicollinearity or other numerical problems.										│
└───────────────────────────────────────────────────────────────────────────────────────────────┘

중요한 값은 테두리(<>)로 표시해 두었습니다. 위에서부터 R-squard는 설명력, Prob(F-statistic)는 유의확률, coef(coefficient)는 계숫값입니다. 이제 지표별로 하나씩 그 의미를 알아보곘습니다. 참고로 Prob(omnibus)는 총괄 검정 유의확률로서 전체 모델의 유의확률이 아니라 오차들이 정규 분포하는지 검증하는 수치입니다. 간단히 말해 이 값이 1에 가까울 수록 오차가 정규분포 되어 있으므로 좋은 회귀 모델이라는 것을 의미합니다.

3. 설명력 지표로 모델 해석하기
설명력 또는 결정 계수(R-squard)란 해당 모델이 관측치에 얼마나 잘 맞는지를 알려주는 지표입니다. 설명력은 0부터 1까지 값을 가지는데, 모델이 완전히 관측치에 들어맞을수록 1에 가까워 집니다. 쉽게 말해 회귀 분석으로 만든 모델이 실제 측정한 값에 얼마나 들어맞는지를 알려주는 지표입니다. 데이터마다 다르지만, 경럼적 관찰에 따르면 0.3에서 0.7 사이에 그 값이 분포합니다.

이 모델에서는 R-squared의 값이 0.097로 너무 낮습니다. 이 값은 직업 만족도라는 변수가 영어 점수 하나만으로는 설명이 되지 않는다는 의미로 해석할 수 있습니다. 반대로 1에 너무 가깝다면 이론이 실제와 너무 잘 맞아떨어져 연구 가치가 없는 것으로 해설될 여지가 있습니다.

4. 유의확률 지표로 모델 해석하기
유의확률인 Prob(F-statistic)의 값은 0.147입니다. 이 값은 0.01 보다도 크고 0.05보다도 큽니다. 즉, 이 값은 전체 모형이 유의하지 않다는 것을 의미합니다. 다시 말해서 영어 점수가 직업 만족도에 직접적으로 영향을 준다고 말할 근거가 부족하다는 것으로도 해석됩니다.

5. 계숫값 지표로 모델 해석하기
English의 coef 값은 -0.0039입니다. 영어 점수가 높을수록 직업 만족도가 낮거나, 영어 점수가 낮을수록 직업 만족도가 높다든가 하는 방향으로 의미가 있을 수 있다는 의미입니다. 하지만 모델 자체가 유의하지 않기 때문에 이 값 또한 큰 의미가 없습니다. 

여기서 외귀 분석 모델이 유의하지 않은 이유는 정상적으로 수집된 데이터를 분석한 것이 아니라, 임의적으로 넣은 숫자로 모델을 만들었기 때문입니다. 실제로 있는 표본을 많이 수집할 수록 회귀 분석 모델은 점점 더 유의해집니다.

6. 다중 회귀 분석 연습
다중 회귀 분석이란 단순 회귀 분석과 달리 두 개 이상의 독립 변수를 사용한다는 의미입니다. 단순 회귀 분석과 하는 방법이 거의 유사합니다.

