06 웹 크롤링으로 정보 모으기

여러분이 프로그래밍 관련 일을 하지 않는다면, 웹 크롤링만큼 여러분의 실생활에 직접적인 도움을 줄 수 있는 기술도 드뭅니다. 이 장에서는 어떻게 실생활에 웹 크롤링을 활용하는지 알아보겠습니다.

06-1 웹 크롤링 알아보기
06-2 웹 크롤링 준비하기
06-3 포털 사이트에서 기사 크롤룅 하기
06-4 프로그램 실행 파일 만들기

06-1 웹 크롤링 알아보기

웹은 끊입없이 커지는 도서관과 같습니다. 새로운 정보가 끊임없이 생겨나죠. 구글 같은 회사가 하는 일 중 하나가 새로 생기는 정보를 구글 검색에 바로 '걸리게'하는 것입니다. 이때 전 세계에서 끊임없이 생산되는 새로운 정보를 모으기 위해 필요한 일이 바로 웹 크롤링(Webcrawling)입니다.

웹 크롤링이란
웹 크롤링이란 웹의 정보를 자동으로 수집하는 것을 의미하며 ㅜ이런 목적을 위해 만든 프로그램을 웹 크롤러라고 말합니다. 섬색 엔진의 아주 원시적인 형태라고 할 수 잇죠. 다른 한 편으로 어두운 해커들의 세계와 연결되어 있기도 합니다. 웹의 정보를 모으는데 웹 크롤링은 아주 매력적인 접근 방법이지만, 한편으로 위험하기도 합니다.

이 책에서는 웹 크롤링의 기본적인 내용만 다룹니다. 제가 웹 크롤링을 배울 때 다른 사람들의 웹 사이트에 있는 스크립트를 그대로 실행해 보면 환경이 바뀐 탓에 제대로 작동하지 않을 때가 많았습니다. 여기서 나온 코드 역시 시간이 지나면 작동하지 않을 수 있습니다. 따라서 제 깃허브(https://github.com/skytreesea/do-it-python)에 실습 코드를 꾸준히 업데이트해 언제든지 작동되는 코드를 사용할 수 있도록 해 두겠습니다.
%해당 코드를 실무에 그대로 사용하지 마십시오. 저자와 출판사는 실무 사용에 따르는 법적인 책임을 지지 않습니다.

HTML 몰라도 웹 크롤링을 할 수 있을까
매일 주요 뉴스를 모아서 텍스트 파일로 저장하고 싶다면 어떤 기술이 필요할까요? 요즘은 블로그 포스팅 등에서도 웹 크롤링을 많이 소개하고 있어 아미 크롤링을 접한 사람도 있을 것입니다. 크롤링을 배우고 싶어서 검색으로 정보를 얻어 보지만, 잠깐 검색한 내용만 가지고 크롤링에 도전해 보기는 쉽지 않죠.

웹 크롤링이라느 ㄴ과정을 온전히 이해가기 위해서는 HTML(하이퍼텍스트 마크업 언어, Hyper Text Markup Language)에 대한 지식이 어느 정도 있어야 합니다. 왜냐하면 웹은 기본적으로 HTML로 만들어져 있기 떄문입니다. 그런데 HTML을 읽을 줄 모른다고요? 걱장하지 마세요. 컴퓨터를 전공하지 않거나, 프로그래밍을 배우지 않은 사람도 크롤링을 할 수 있게 하는 것이 이 장의 목적입니다. 저 역시 HTML이나 CSS의 모든 것을 알고 있지 않습니다. 웹 크롤링이 목적이라면 전부를 알 필요는 없기 떄문입니다.

인터넷에는 중요한 자료가 정말 없을까
'인터넷에는 중요한 자료가 없다'는 말이 있죠? 이제 새삼 반박할 필요도 없겠지만, 이 세상에 거의 모든 정보는 인터넷에 있다고 해도 과언이 아닙니다. 심지어는 저작권이 없어진 고전들 역시 구텐베르크 사이트에서 무료로 볼 수 있습니다. 그뿐만 아니라, 조선왕조실록 등 사료들 역시 인터넷 사이트에 체계적으로 정리가 잘 되어 있습니다. 몰론 이것을 가공해 활요하는 것은 사람의 몫이겠지만, 이제 인터넷에 중요한 자료가 없다고 말하기는 힘들곘죠?

최신 학문적 논의 역시 구글 스칼라나 위키피디아에 잘 정리되어 있습니다. 많은 사람이 위키피디아에 '전문적 자료가 없다'고 말하기도 합니다만, 위키피디아만큼 어떤 주제에 대해서 핵심적인 내용을 체계적으로 정리해 놓은 사이트는 드뭅니다. 박사학위를 마친 연구자가 감사의 글에 '고마워요, 위키(Thank you. Wikipedia)'라고 썼다는 우스갯소리가 나올 정도이지요. 이것도 벌써 엄청나게 오랜된 유머입니다.

수많은 정보를 어떻게 활용할까
크롤링은 필요한 자료를 빠른 시간에 수집할 수 있는 엄청나게 강력한 도구입니다. 때로는 웹사이트로부터 너무나 쉽게 정보를 획득할 수 있어서 약간은 위험하다고 느낄 만큼 엄청난 정보를 얻어낼 수 있습니다.

아주 간단한 예로 지금 당장 코스피 상위 200개 종목의 주가를 한 번에 확인해서 그래프로 출력하고 싶을 때, 웹 크롤링으로 필요한 자료를 쉽손게 가져올 수 있습니다. 몰론 이런 기능은 증권사 HTS에서 너무나 잘 구현되어 있습니다만, 자기만의 자료 수집 방식을 가진다는 것은 엄청나게 매력적인 일입니다.

앞으로 소개할 웹 클롤링 관룐 코드는 연구 직종에 종사하고 있는 제가 개인적인 필요를 위해서 제작했던 것입니다. 저는 이런 웹 크롤링의 도움을 많이 받았으며, 이것을 잘 활용하면 다른 사람들이 따라오기 힘들 정도의 생산력을 발휘할 수 있습다고 믿습니다.

%알아보면 좋아요 - 데이터 수집 시 주의할 점
본격적으로 시작하기 전에 먼저 주의할 사항이 있습니다. 먼저 클롤링의 세계는 인터넷의 크기만큼이나 무한하지만, 이 책에서 언급하는 크롤링의 범위는 매우 제한적이라는 점입니다. 크롤링의 세계는 결국 해킹의 세계와도 연결됩니다. 처음에는 크롤링이나 스크래핑(scraping)에 만족하다가 나중에는 암호화된 정보에 접근하고 싶은 욕망이 생길지도 모릅니다. 이 책에서는 크롤링 중에서도 아주 파편적이며 매우 제한적인 부분만 다룹니다. 다시 말해 신문 기사를 모을 수 있는 정도의 크롤링 기법만을 설명합니다. 그런데 이러한 크롤링이 가능하다는 사실에 알게 되고, 또 실습을 하다 보면, 데이터를 보는 눈이 달라집니다. 같은 문제로 정보를 검색하더라도 어떤 부분은 자동화할 수 있겠다는 감을 잡게 해주는 것이 이 장의 목적 입니다.

또 하나의 유의할 점은 크롤링의 접근 방식은 법적 문제를 일으킬 수 있다는 점입니다. '크롤링 남의 자산 훔치는 범죄행위, 인식 변화 갖자'라는 무시무시한 제목의 시가(IT 조선, 박철현 기자, 2019.05.07.)가 있을 정도입니다. 그런데 해당 기사에서 언급하고 있듯이, 크롤링 대부분은 위법이 아닙니다. '하지만 웹페이지의 운영자가 긁어가지 못하도록 조치한 데이터를 긁어간다거나, 긁어간 데이터를 사용해 부당이득을 얻는다거나 하는 행위를 할 경우엔 저작권법이나 부정경쟁방지법 등의 재재를 받을 수 있다.'고 이기사는 설명하고 있습니다.

이 책에서 공개하는 크롤링 방식은 지극히 개인적이고 파편적인 수준이며, 상업적 가치가 있는 데이터에 접근을 시도할 때 발생할 수 있는 어떠한 상황에 대래서는 책임을 질 수 없습니다. 하지만 크롤링 자체는 검색 서비스를 비롯한 전 세계의 수많은 프로그래머가 웹의 저옵를 모으는 아주 일반적인 방식이라는 점은 짚고 넘어가겠습니다.

06-2 웹 크롤링 준빈하기

여러분, 명언 좋아하나요? 저는 유염인의 어록을 종종 찾아 읽습니다. 그 사람의 인생과 철학이 느껴지거든요. 예를 들어 '내가 조금 더 보았다면, 그건 거인의 어깨 위에 서 있기 때문이다.(if i have seen further it is by standing on the shoulders of Giants.).'라는 뉴턴의 명언을 읽으면 그가 얼마나 겸손했는지를 느낄 수 있지요. 게다가 영어 공부는 덤으로 되고요. 그럼 이런 명언이 모여 있는 웹 사이트에서 크롤링을 통해 명언을 수집해 보겠습니다.

이런 생활이라면?
웹 사이트에서 명언을 수집하자
영어 명언 수집하는 것을 좋아하는 저에게 한 친구가 명언을 모아 놓은 웹 사이틀를 추천해 주었습니다. 접속해 보니 그야말로 명언 천국이네요. 아인슈타인의 명언부터 해리포터 시리즈의 점블도어 교장 선생님의 대사까지 '명언'으로 꽉 차 있네요. 그런데 일일이 옮겨 적으려니 시간이 너무 많이 들 것 같습니다. 문서 파일에 한 번에 모아서 저장할 수 없을까요?

'quotes to scrape'라는 사이틀 소개합니다.(https://quotes.toscrape.com/). 이 사이트는 말 그대로 스크랩(scrap)하기 좋은 명언을 정리해 놓은 사이트입니다. 이 사이트의 명언을 엑셀 파일로 만드어서 관리하고 싶은데요.

그러기 위해서 명언을 하나씩 복사해 옭기는 방법이 있을 겁니다. 아직도 코드 자기가 귀찮아서 필요한 내용을 종종 이렇게 마우스로 긁어서 가져올 때가 있습니다. 하지만 양이 늘어나면 그 작업 자체가 쉽지 않을뿐더러, 마우스가 제대로 움직이지 않아서 힘이 들곤 합니다.

반복은 컴퓨터가 훨씬 잘하다고 했지요? 바로 이럴 때 웹 크롤러를 만들면 명언을 쉽게 가져올 수 있습니다. 이 사이트를 활요해 웹 크롤링을 간단히 실습해 보죠.

Quotes to scrape 페이지 살펴보기
짜, 머넞 사이트를 그냥 한번 들여다보겠습니다. 먼저 사이트가 어떻게 생겼는지 알아야 사이트에서 어떻게 저옵를 얻어낼지 생각할 수 있습니다. 명언을 살펴보니 문장마다 밑에 태그 가 붙어있고, 오른쪽에는 가장 많이 쓰인 태그가 나열되어 있습니다. 여기서 <life>를 클릭해 보겠습니다.

다음과 같이 'life'라는 태크로 된 화면으로 넘어갑ㄴ디ㅏ. '세상에는 두 종류의 삶이 있다. 하나 기적이란 하나도 없는 인생이다. 다른 하나는 모든 것이 기적인 삶이다.'라는 아인슈타인의 명언이 있네요. 여기서 <(about)>을 클릭해 볼까요?

해당 인물의 정보가 나오네요. 인물 정보도 따로 모아볼 수 있겠네요.

이전 페이지로 돌아가 스크롤을 내려 보면 <Next> 버튼이 있습니다. 클릭해 볼까요?

클릭하면 다음 화면으로 넘어가면서 새로운 명언들이 나오는 것을 볼 수 있스빈다. 밑에 있는 <previous> 번튼을 누르면 다시 이전 페이지로 돌아갑니다.

지금까지 Quotes to scrape 사이트가 어떻게 생겼는지 간단히 살펴보았습니다. 지그은 웹사이트에 접속해서 정보를 얻어내는 것이 일상화되어 있어 웹 사이트의 특성을 알아내는 일은 식은 죽 먹기라 생각했을지도  모르겠습니다. 그런데 웹 사이트 둘러보기로 두 가지 사실을 알았습니다.

먼저, 이 사이트의 명언들은 태그별로 모여 있다는 사실입니다. 인생(life)과 사랑(love)에 대한 명언을 태그별로 모으는 것도 가능합니다. 또한, 한 페이지에 일정 수의 명언만 보이고 나너지는 다음(Next) 페이지에 저장되어 있다는 사실을 확인했습니다.

자, 그렇다면 앞으로 해야 할 일은 다음과 같이 정의할 수 있겠습니다. 먼저 웹 사이트에 접속해서 한 태그의 명어늘 긁어옵니다. 그리고 다음(Next) 페이지로 이동해 명언을 계속 긁어옵니다. 다음 페이지가 ㅇㅄ다면 다른 태그로 넘어갑니다. 이 과정은 복잡하고 어려운 작업까지 이어질 수 있지만, 차근차근히 진행해 보겠습니다.

1. 'Quotes to scrape'페이지를 불러와서 객체에 저장한다.
2. 브라우저ㅗ에서 명언이 았는 위치를 확인한다.
3. 각 태그에 맞는 명언을 찾아서 출력한다.

뷰티풀수프 설치하기
파이써능로 웹 크롤링을 하기 위해 먼저 뷰티풀수프(BeautifulSoup)를 설치하겠습니다. 뷰티풀수프는 웹 문서를 구성하는 HTML과 XML 문서에서 원하는 정보를 쉽게 추출할 수 있는 모듈을 모아 놓은 파이썬 패키지입니다. 아나콘다에 포함되어씨지 않아 별도로 설치를 꼭 햐야 합니다.
%셀레니움(selenium)의 웹드라이버(webdriveer)로 브라우저를 제어하는 방법도 있지만 여기서는 뷰티풀수프 패키지를 이용한 스크래핑(scraping)만 알아보겠습니다.

pip를 사용하면 패키지를 쉽게 설치할 수 있습니다. 명령 프롬프트 창을 열고 다음 명령을 입력해 뷰티풀수프 패키지를 설치하세요.

C:\User\user>pip install beatifulsoup4


기분 모듈 임포트 하기
본격적으로 코드를 작성하기 전에 필요한 것 같은 모듈을 미리 불러오겠습니다. 웹 크롤링 실습에는 어떤 모듈이 필요할까요? 먼저 지금까지 항상 써 왔던 운영체제 모듈 os, 정규식 모듈 re, 그리고 앞에서 만들었던 CSV 파일을 저장할 때 필요한 usercsv 모듈을 임포트 하겠습니다.

>>> import os, re, usercsv

이제 웹 크롤링을 하기 위해 새로 알아야 할 모듈을 살펴보겠습니다. 먼저 requests는 URL주소에 있는 내용을 요청할 때 사용하는 모듈입니다. os, re와 마찬가지로 파이썬에 내장되어 있어 바로 임포트 하면 됩니다.

>>> import requests

다음으로 urllib, request 모듈을 임포트 하겠습니다. urllib은 웹에서 얻은 데이터를 다루는 파이썬 패키지입니다. 이 패키지 안에는 총 네 개의 모듈이 있는데, 이중 웹 문서를 열어 데이터를 읽어오는 request 모듈을 사용하겠습니다.



